{"meta":{"title":"地字第一号","subtitle":"重庆·嘉陵江·望江阁","description":"","author":"归海一刀","url":"http://example.com","root":"/"},"pages":[{"title":"分类","date":"2020-09-12T07:09:52.000Z","updated":"2020-09-14T07:49:27.797Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-09-14T07:49:01.000Z","updated":"2020-09-14T07:48:20.902Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Unix和Linux操作系统有什么区别","slug":"Unix和Linux操作系统有什么区别","date":"2020-09-25T06:22:55.000Z","updated":"2020-09-25T06:50:37.233Z","comments":true,"path":"2020/09/25/Unix和Linux操作系统有什么区别/","link":"","permalink":"http://example.com/2020/09/25/Unix%E5%92%8CLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/","excerpt":"","text":"Unix和Linux操作系统有什么区别Unix和Linux操作系统有什么区别UNIX、Linux是多用户多任务操作系统;Windows操作系统是单用户多任务操作系统Linux下，我们可能使用虚拟终端来使得多个用户同时工作。而windows下，每次只允许一个用户登陆系统。 Unix于1969年由贝尔实验室开发出来，使用至今已变更了很多个版本。目前主流的Unix系统有三种，分别是AIX、HP-UX、Solaris，这些Unix系统互不兼容。 Linux于1991年由芬兰大学生Linus开发出来，是一个类Unix系统，但是其代码不源自任何Unix版本，完全不是Unix的一个分支，而是一个开源版的模仿。 现在Linux主要使用在PC机和嵌入式，或者一些小型企业的服务器；而Unix垄断着大型企业的关键性应用领域。 unix是在posix之前就有的，linux是在posix出来之后有的，最初的linux是仿制的minix，unix和linux很多软件都是相通的，linux是UNIX的一个分支，别的分支还有freebsd等，UNIX是命令行下的系统 linux是加了窗体管理的系统。 UNIX是一个功能强大、性能全面的多用户、多任务操作系统，可以应用从巨型计算机到普通PC机等多种不同的平台上，是应用面最广、影响力最大的操作系统。 Linux是一种外观和性能与UNIX相同或更好的操作系统，但，Linux不源于任何版本的UNIX的源代码，并不是UNIX，而是一个类似于UNIX的产品。 从发展的背景看，Linux是从UNIX发展而来的。这种继承使得Linux的用户能大大地从UNIX团体贡献中获利。因为UNIX是世界上使用最普遍、发展最成熟的操作系统，它是七十年代中期发展起来的微机和巨型机的多任务系统，虽然有时接口比较混乱，并缺少相对集中的标准，但还是发展壮大成为了最广泛使用的操作系统之一。UNIX的用户可以从很多方面得到支持和帮助。因此，Linux做为UNIX的一个克隆，同样会得到相应的支持和帮助，直接拥有UNIX在用户中建立的牢固的地位。 从使用费用上看，UNIX与Linux的区别在于Linux是一种开放、免费的操作系统，而UNIX系统基本上需要有偿使用。这一区别使得我们能够不用花钱就能得到很多Linux的版本以及为其开发的应用软件。当我们访问Internet时，会发现几乎所有可用的自由软件都能够运行在Linux系统上。并且，一大批世界级的优秀的程序员正在努力开发和提供基于Linux的共享软件。 但是，也正是由于Linux源码可以开放的缘故，所以现在真正的商业应用尚未开始，原因很简单：任何人都可以了解其内部最薄弱的环节，都可以实施侵袭和攻击。 从产品方面看，UNIX和Linux都是操作系统的名称．但UNIX这四个字母除了是操作系统名称外，还作为商标归SCO所有．Linux商业化的有RedHat Linux 、SuSe Linux、slakeware Linux、国内的红旗等，还有Turbo Linux.UNIX主要有Sun 的Solaris、IBM 的AIX, HP的HP-UX，以及x86平台的的SCO UNIX/UNIXwareUNIX多数是硬件厂商针对自己的硬件平台的操作系统，主要与CPU等有关，如Sun 的Solaris作为商用，定位在其使用SPARC/SPARCII的CPU的工作站及服务器上，当然Solaris也有x86的版本，而Linux也有其于RISC的版本。 至于价格，个人使用的Linux基本上算是免费的，不同的Linux发行厂商针对企业级应用在基本的系统上有些优化，如RedHat的Enterprise产品，这些产品包括支持服务是比较贵的。像IBM/HP/SUN的UNIX，因为主要是针对其硬件平台，所以操作系统通常在设备价格中。 在性能上，Linux没有UNIX那么全面，但基本上对个人用户和小型应用来说是绰绰有余．通常情况下，如果你有机会使用到UNIX环境，比如银行、电信部门，那一般都是固定机型的UNIX。比如电信里SUN的居多，民航里HP的居多，银行里IBM的居多。学习中，不同的UNIX命令集有些不同，要注意。 UNIX 与 Linux 之间的关系是一个很有意思的话题。在目前主流的服务器端操作系统中，UNIX 诞生于 20 世纪 60 年代末，Windows 诞生于 20 世纪 80 年代中期，Linux 诞生于 20 世纪 90 年代初，可以说 UNIX 是操作系统中的”老大哥”，后来的 Windows 和 Linux 都参考了 UNIX。 现代的 Windows 系统已经朝着“图形界面”的方向发展了，和 UNIX 系统有了巨大的差异，从表面上甚至看不出两者的关联。 UNIX 的坎坷历史UNIX 操作系统由肯•汤普森（Ken Thompson）和丹尼斯•里奇（Dennis Ritchie）发明。它的部分技术来源可追溯到从 1965 年开始的 Multics 工程计划，该计划由贝尔实验室、美国麻省理工学院和通用电气公司联合发起，目标是开发一种交互式的、具有多道程序处理能力的分时操作系统，以取代当时广泛使用的批处理操作系统。 说明：分时操作系统使一台计算机可以同时为多个用户服务，连接计算机的终端用户交互式发出命令，操作系统采用时间片轮转的方式处理用户的服务请求并在终端上显示结果（操作系统将CPU的时间划分成若干个片段，称为时间片）。操作系统以时间片为单位，轮流为每个终端用户服务，每次服务一个时间片。 可惜，由于 Multics 工程计划所追求的目标太庞大、太复杂，以至于它的开发人员都不知道要做成什么样子，最终以失败收场。 以肯•汤普森为首的贝尔实验室研究人员吸取了 Multics 工程计划失败的经验教训，于 1969 年实现了一种分时操作系统的雏形，1970 年该系统正式取名为 UNIX。 想一下英文中的前缀 Multi 和 Uni，就明白了 UNIX 的隐意。Multi 是大的意思，大而且繁；而 Uni 是小的意思，小而且巧。这是 UNIX 开发者的设计初衷，这个理念一直影响至今。 有意思的是，肯•汤普森当年开发 UNIX 的初衷是运行他编写的一款计算机游戏 Space Travel，这款游戏模拟太阳系天体运动，由玩家驾驶飞船，观赏景色并尝试在各种行星和月亮上登陆。他先后在多个系统上试验，但运行效果不甚理想，于是决定自己开发操作系统，就这样，UNIX 诞生了。 自 1970 年后，UNIX 系统在贝尔实验室内部的程序员之间逐渐流行起来。1971-1972 年，肯•汤普森的同事丹尼斯•里奇发明了传说中的C语言，这是一种适合编写系统软件的高级语言，它的诞生是 UNIX 系统发展过程中的一个重要里程碑，它宣告了在操作系统的开发中，汇编语言不再是主宰。 到了 1973 年，UNIX 系统的绝大部分源代码都用C语言进行了重写，这为提高 UNIX 系统的可移植性打下了基础（之前操作系统多采用汇编语言，对硬件依赖性强），也为提高系统软件的开发效率创造了条件。可以说，UNIX 系统与C语言是一对孪生兄弟，具有密不可分的关系。 20 世纪 70 年代初，计算机界还有一项伟大的发明——TCP/IP 协议，这是当年美国国防部接手 ARPAnet 后所开发的网络协议。美国国防部把 TCP/IP 协议与 UNIX 系统、C语言捆绑在一起，由 AT&amp;T 发行给美国各个大学非商业的许可证，这为 UNIX 系统、C语言、TCP/IP 协议的发展拉开了序幕，它们分别在操作系统、编程语言、网络协议这三个领域影响至今。肯•汤普森和丹尼斯•里奇因在计算机领域做出的杰出贡献，于 1983 年获得了计算机科学的最高奖——图灵奖。 图 1 为肯•汤普森与丹尼斯•里奇的合影，天才都是不修边幅的…… 随后出现了各种版本的 UNIX 系统，目前常见的有 Sun Solaris、FreeBSD、IBM AIX、HP-UX 等。 Solaris 和 FreeBSD我们重点介绍一下 Solaris，它是 UNIX 系统的一个重要分支。Solaris 除可以运行在 SPARC CPU 平台上外，还可以运行在 x86 CPU 平台上。在服务器市场上，Sun 的硬件平台具有高可用性和高可靠性，是市场上处于支配地位的 UNIX 系统。 对于难以接触到 Sun SPARC 架构计算机的用户来说，可以通过使用 Solaris x86 来体验世界知名大厂的商业 UNIX 风采。当然，Solaris x86 也可以用于实际生产应用的服务器，在遵守 Sun 的有关许可条款的情况下，Solaris x86 可以免费用于学习研究或商业应用。 FreeBSD 源于美国加利福尼亚大学伯克利分校开发的 UNIX 版本，它由来自世界各地的志愿者开发和维护，为不同架构的计算机系统提供了不同程度的支持。FreeBSD 在 BSD 许可协议下发布，允许任何人在保留版权和许可协议信息的前提下随意使用和发行，并不限制将 FreeBSD 的代码在另一协议下发行，因此商业公司可以自由地将 FreeBSD 代码融入它们的产品中。苹果公司的 OS X 就是基于 FreeBSD 的操作系统。 FreeBSD 与 Linux 的用户群有相当一部分是重合的，二者支持的硬件环境也比较一致，所采用的软件也比较类似。FreeBSD 的最大特点就是稳定和高效，是作为服务器操作系统的不错选择；但其对硬件的支持没有 Linux 完备，所以并不适合作为桌面系统。 其他 UNIX 版本因应用范围相对有限，在此不做过多介绍。 Linux 的那些往事Linux 内核最初是由李纳斯•托瓦兹（Linus Torvalds）在赫尔辛基大学读书时出于个人爱好而编写的，当时他觉得教学用的迷你版 UNIX 操作系统 Minix 太难用了，于是决定自己开发一个操作系统。第 1 版本于 1991 年 9 月发布，当时仅有 10 000 行代码。 李纳斯•托瓦兹没有保留 Linux 源代码的版权，公开了代码，并邀请他人一起完善 Linux。与 Windows 及其他有专利权的操作系统不同，Linux 开放源代码，任何人都可以免费使用它。 据估计，现在只有 2% 的 Linux 核心代码是由李纳斯•托瓦兹自己编写的，虽然他仍然拥有 Linux 内核（操作系统的核心部分），并且保留了选择新代码和需要合并的新方法的最终裁定权。现在大家所使用的 Linux，我更倾向于说是由李纳斯•托瓦兹和后来陆续加入的众多 Linux 好者共同开发完成的。 李纳斯•托瓦兹无疑是这个世界上最伟大的程序员之一，何况，他还搞出了全世界最大的程序员交友社区 GitHub (开源代码库及版本控制系统）。 关于 Linux Logo 的由来是一个很有意思的话题，它是一只企鹅。 为什么选择企鹅，而不是选择狮子、老虎或者小白兔？有人说因为李纳斯•托瓦兹是芬兰人，所以选择企鹅，有人说因为其他动物图案都被用光了，李纳斯•托瓦兹只好选择企鹅。 我更愿意相信以下说法，企鹅是南极洲的标志性动物，根据国际公约，南极洲为全人类共同所有，不属于世界上的任何国家，可国家都无权将南极洲纳入其版图。Linux 选择企鹅图案作为 Logo，其含义是：开放源代码的 Linux 为全人类共同所有，可公司无权将其私有。 UNIX与Linux的亲密关系二者的关系，不是大哥和小弟，”UNIX 是 Linux 的父亲”这个说法更怡当。之所以要介绍它们的关系，是因为要告诉读者，在学习的时候，其实 Linux 与 UNIX 有很多的共通之处，简单地说，如果你已经熟练掌握了 Linux，那么再上手使用 UNIX 会非常容易。 二者也有两个大的区别： UNIX 系统大多是与硬件配套的，也就是说，大多数 UNIX 系统如 AIX、HP-UX 等是无法安装在 x86 服务器和个人计算机上的，而 Linux 则可以运行在多种硬件平台上； UNIX 是商业软件，而 Linux 是开源软件，是免费、公开源代码的。 Linux 受至旷大计算机爱好者的喜爱，主要原因也有两个： 它属于开源软件，用户不用支付可费用就可以获得它和它的源代码，并且可以根据自己的需要对它进行必要的修改，无偿使用，无约束地继续传播； 它具有 UNIX 的全部功能，任何使用 UNIX 操作系统或想要学习 UNIX 操作系统的人都可以从 Linux 中获益。 开源软件是不同于商业软件的一种模式，从字面上理解，就是开放源代码，大家不用担心里面会搞什么猫腻，这会带来软件的革新和安全。 另外，开源其实并不等同于免费，而是一种新的软件盈利模式。目前很多软件都是开源软件，对计算机行业与互联网影响深远。 开源软件本身的模式、概念比较晦涩，这套《Linux教程》旨在指导读者应用 Linux，大家简要理解即可。 近年来，Linux 已经青出于蓝而胜于蓝，以超常的速度发展，从一个丑小鸭变成了一个拥有庞大用户群的真正优秀的、值得信赖的操作系统。历史的车轮让 Linux 成为 UNIX 最优秀的传承者。 总结一下 Linux 和 UNIX 的关系/区别Linux 是一个类似 Unix 的操作系统，Unix 要早于 Linux，Linux 的初衷就是要替代 UNIX，并在功能和用户体验上进行优化，所以 Linux 模仿了 UNIX（但并没有抄袭 UNIX 的源码），使得 Linux 在外观和交互上与 UNIX 非常类似。 说模仿可能会被人喷，你也可以说微创新或者改进。 相比于 UNIX，Linux 最大的创新是开源免费，这是它能够蓬勃发展的最重要原因；而目前的 UNIX 大部分都是收费的，小公司和个人都难以承受。 正是由于 Linux 和 UNIX 有着千丝万缕的联系，所以人们把 Linux 叫做“类UNIX系统”，下节我们将会着重讲解。 UNIX/Linux系统结构UNIX/Linux 系统可以粗糙地抽象为 3 个层次（所谓粗糙，就是不够细致、精准，但是便于初学者抓住重点理解），如图 3 所示。底层是 UNIX/Linux 操作系统，即系统内核（Kernel）；中间层是 Shell 层，即命令解释层；高层则是应用层。 图 3 UNIX/Linux 系统结掏层次概要 1) 内核层内核层是 UNIX/Linux 系统的核心和基础，它直接附着在硬件平台之上，控制和管理系统内各种资源（硬件资源和软件资源），有效地组织进程的运行，从而扩展硬件的功能，提高资源的利用效率，为用户提供方便、高效、安全、可靠的应用环境。 2) Shell层Shell 层是与用户直接交互的界面。用户可以在提示符下输入命令行，由 Shell 解释执行并输出相应结果或者有关信息，所以我们也把 Shell 称作命令解释器，利用系统提供的丰富命令可以快捷而简便地完成许多工作。 3) 应用层应用层提供基于 X Window 协议的图形环境。X Window 协议定义了一个系统所必须具备的功能（就如同 TCP/IP 是一个协议，定义软件所应具备的功能），可系统能满足此协议及符合 X 协会其他的规范，便可称为 X Window。 现在大多数的 UNIX 系统上（包括 Solaris、HP-UX、AIX 等）都可以运行 CDE （Common Desktop Environment，通用桌面环境，是运行于 UNIX 的商业桌面环境）的用户界面；而在 Linux 上广泛应用的有 Gnome（见图 4）、KDE 等。 图 4 Gnome图形界面 X Window 与微软的 Windows 图形环境有很大的区别： UNIX/Linux 系统与 X Window 没有必然捆绑的关系，也就是说，UNIX/Linux 可以安装 X Window，也可以不安装；而微软的 Windows 图形环境与内核捆绑密切。 UNIX/Linux 系统不依赖图形环境，依然可以通过命令行完成 100% 的功能，而且因为不使用图形环境还会节省大量的系统资源。 作为服务器部署，绝大多数 Linux 并不安装或并不启用图形环境，本教程的讲解也基本上为 Linux 命令行下的操作。 FreeBSD可以说是正统的Unix，以FreeBSD和Linux区别说明：Linux 是一个采用GPL 许可证第二版(GPLv2) 的操作系统内核。由于它只是一个操作系统内核，其生态系统的完善必须依靠东拼西凑。举例来讲，Ubuntu、CentOS、Arch 等发行版都是 Linux 内核 +GNU 套件（有时也会称为 “base” 或者 “userland”）+ 应用软件的组合。普通开发者以及用户所理解的「能干活」的最小系统，至少需要 Linux 内核 + GNU 套件。当然 GNU 套件理论上并不是必须，例如嵌入式领域常用 BusyBox 代替 GNU 套件，另外还有 Android 这类默认不需要 shell 交互的 Linux 发行版存在。Linux 用户可以自行脑补一下从开机引导到进入 shell，再运行几个基本命令比如ls、cd、cat等这套完整流程。 传染的 GPL 许可证 由于历史局限性，GPL 许可证在发布当年并没有覆盖云服务的使用场景，使得云服务可以合法绕过其强制开源条款向用户提供服务，间接促成了 Linux 在服务器领域的繁荣。十余年后出现了试图亡羊补牢却于事无补的 AGPL 许可证，此乃后话，按下不表。 然而，在方兴未艾的 IoT 领域，物联网设备的物理分发必要性使得采用 Linux 的嵌入式产品面临严峻的许可证问题。与云服务不同，嵌入式设备的使用场景通常会触发 GPL 的强制开源条款。尽管这个笼统的描述在法律上并不简单等同于「设备使用了 Linux 就必须开源」，但是 GPL 的传染性无疑会极大增加技术选型以及合规成本。 不谈法律细节，许可证是非常严肃的问题，忽视许可证风险将给产品和公司带来巨大的不可控因素。GPL 许可证造成的著名纠纷案例可以参考被强制开源的 Linksys WRT54G 无线路由器固件（后来发展成为 OpenWrt），在此不予赘述。 同样由于历史原因，在某些忽视版权的国家和地区，Linux 在嵌入式领域曾经大行其道。然而随着全球化进程的加深，越来越多的公司意识到版权问题的重要性。在特殊时期，知识产权陷阱更会成为遏制公司甚至是国家发展的武器。基于 Linux 的物联网设备极有可能深陷 Linksys WRT54G 那样的 GPL 合规泥潭，轻则付出合规与罚款代价，重则被强制开源并丧失商业机密，甚至遭遇全面禁售。 混乱的发行模式 看似百花齐放，实际上 Linux 各发行版的区别并不大。除去技术细节，各发行版最主要的差异在于社区性质（用户数量及质量）、技术支持水平（与社区相关）以及不同偏好，例如包管理系统等。 几乎所有的 Linux 发行版都将 Linux 内核、GNU 套件以及应用软件混为一谈，也就是采用同样的包管理器管理所有组件。这三个部分本来分属若干独立团体，彼此之间并无强耦合关系，却常常被强行锁定版本捆绑在一起发布（特别是非滚动更新发行版）。与系统稳定性紧密相关的核心组件往往和应用软件享有同样的优先级，例如全部配置文件都被塞到 /etc 下，无原则混用 /usr 与 /usr/local 等。 云服务常用的 LTS (Long Term Support) 发布模式 Linux 系统中，为了「稳定性」，很多被业务重度依赖的应用软件偏偏被锁定在当前 LTS 版本发布时的低版本，并且在今后的 LTS 生命周期（一般是好几年）内得不到任何新版本更新（只会获得重要的安全更新）。这就是将所有组件混为一谈的恶果。 在实际生产环境中，为了某些应用软件只有新版本才有的新功能，运维不得不开启非官方仓库以求获得新版本支持。更有甚者不惜触犯运维大忌，干脆人为绕过包管理系统，采取自行编译并「山寨」安装的下下策。 这种一刀切的粗粒度发行模式本身就是极其不合理的奇葩设计，由此产生的各种丑陋的变通方案更是折射出 Linux 社区的精分、痛苦、纠结与挣扎。人人都不满意，人人都想要「更合理」的方案，这也是为什么 Linux 发行版层出不穷的原因。一次次重复发明轮子的行为，使得 Linux 的碎片化问题日益严重。 近年来兴起的容器技术（例如 Docker）可以部分看作是对以上粗粒度发行模式的反抗：既然每次吃饭都会无可避免弄脏手，我们不妨吃完饭就砍掉脏手，再等新的长出来，这样不至于因为弄脏手而把整个人埋掉。 可是，难道就没有人能体面一点使用餐具么？？？ 生态高度统一的 x86 市场尚且如此艰辛，更何况是生态多样的 ARM 移动设备市场。Google 使劲浑身解数，仍然无法遏制住 Android 的碎片化趋势，这些都是历历在目的前车之鉴。可想而知，在目前几乎呈现原生态的广阔 IoT 市场，选择 Linux 就注定选择了混乱和颠沛流离。 FreeBSD与东拼西凑的 Linux 发行版不同，源自 BSD 的 FreeBSD 是一套完整的操作系统。FreeBSD 可以说是正统的 Unix，比 Linux 的历史更为悠久。FreeBSD 在今天不如 Linux 流行，是因为若干年前那场 BSD 与 AT&amp;T 的版 (sī) 权 (bī) 纠 (dà) 纷 (zhàn)。待到几年后尘埃落定，FreeBSD 也遗憾地错过了服务器市场爆发的黄金时期。 风水轮流转，在当前 IoT 市场高速发展的新时期，FreeBSD 正以全新的姿态强势回归。 宽松的 BSD 许可证 FreeBSD 采用的两句版 BSD 许可证不要求衍生作品开源，除了保留原始版权声明的要求之外，没有其他的限制，因此对商业使用场景来说非常友好，特别是在物联网设备的嵌入式应用场景下。 严谨的发行模式 FreeBSD 内核与基本系统 (base system) 作为一个整体绑定发行（以下简称「系统」），有三个发行分支，分别为 CURRENT、STABLE 以及 RELEASE，在升级路线上也高度一致。其中 RELEASE 分支采用二进制升级方式，剩下两个分支采用源代码编译升级方式。整体发行的好处在于提高系统一致性、健壮性与稳定性。 FreeBSD 的应用软件采用独立于系统的包管理方案。还能提供同一软件的不同版本选择，不需要像非滚动更新的 Linux 发行版常见的错误做法那样粗暴地将应用软件版本与整个系统锁定。 以 Python 为例，在 FreeBSD 下不仅有 2.7，还有 3.5、3.6 和 3.7 一共四个版本： 12345[si@sys ~]$ pkg search python | grep Interpretedpython27-2.7.16_1 Interpreted object-oriented programming languagepython35-3.5.7_2 Interpreted object-oriented programming languagepython36-3.6.9 Interpreted object-oriented programming languagepython37-3.7.3_1 Interpreted object-oriented programming language 类似的，Node.js 也有 6.x、8.x、10.x 以及 12.x 这四个版本可供选择： 12345[si@sys ~]$ pkg search node | grep V8node-12.4.0 V8 JavaScript for client and servernode10-10.16.0 V8 JavaScript for client and servernode6-6.17.1 V8 JavaScript for client and server (6.x LTS)node8-8.16.0 V8 JavaScript for client and server (8.x LTS) 多版本共存的理念贯穿大多数对版本敏感的软件，比如 PHP、MariaDB、PostgreSQL 等。Linux 发行版（特别是 CentOS）如同噩梦般的软件版本问题，在 FreeBSD 下竟然完全不存在。 系统与软件的清晰隔离也体现在 FreeBSD 的文件组织结构上。例如，/usr 与 /usr/local 有严格区分，前者为系统文件路径，后者为软件文件路径，根据路径可以直观地识别出用户自行安装的部分。 不难看出，FreeBSD 这套强大的系统管理方案同时兼顾稳定性、易用性与定制性： freebsd-update: 管理内核与基本系统的二进制升级 pkg: 管理使用默认参数编译好的二进制软件包 Ports: 管理软件包源代码以供自定义编译 熟悉 Linux 的人也许会发现，FreeBSD 的包管理方案实际上大约等于以下两大 Linux 发行版包管理器的完美合体： Arch: pacman，对应 pkg（秉承同样 KISS 理念） Gentoo: Portage，对应 Ports（Portage 本身就是 Ports 的仿制品） 然而，Linux 发行版并没有类似 freebsd-update 那样的系统二进制升级方案。 比较而言，FreeBSD 的发行模式更类似于 Windows。FreeBSD 的版本号对应 Windows 版本号，例如 Windows XP、Windows 7、Windows 10 等；FreeBSD 的基本系统对应 Windows 默认安装（包含内置工具与程序，例如控制面板、记事本、画图等）；而 FreeBSD 的应用软件则对应 Windows 上由用户自行安装的第三方程序。 低调的巨人 令人惊奇的是，与日常认知不同，FreeBSD 并不小众，在很多商业产品里都能看到 FreeBSD 的身影。以下是几个著名产品的例子： 这些产品的成功在一定程度上都归功于 FreeBSD 出色的性能以及商业友好的许可证。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"unix","slug":"unix","permalink":"http://example.com/tags/unix/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"Serverless","slug":"serverless","date":"2020-09-25T01:02:38.000Z","updated":"2020-09-25T01:41:07.881Z","comments":true,"path":"2020/09/25/serverless/","link":"","permalink":"http://example.com/2020/09/25/serverless/","excerpt":"","text":"前言最近关于 Serverless 的讨论越来越多。看似与前端关系不大的 Serverless，其实早已和前端有了颇深渊源，并且将掀起新的前端技术变革。此次分享根据个人理解和总结，从前端开发模式在serverless的演进、Serverless 常见服务商提供的解决方案以及 基于Serverless 的前端开发模式等方面，与大家探讨 Serverless 中的前端开发模式。一、前端开发模式的演进 首先回顾一下前端开发模式的演进，我觉得主要有四个阶段。。1、基于模板渲染的动态页面 2、基于 AJAX 的前后端分离 3、基于 Node.js 的前端工程化 4、基于 Node.js 的全栈开发 基于模板渲染的动态页面在早起的互联网时代，我们的网页很简单，就是一些静态或动态的页面，主要目的是用来做信息的展示和传播。这个时候开发一个网页也很easy，主要就是通过 JSP、PHP 等技术写一些动态模板，然后通过 Web Server（nginx，apache） 将模板解析成一个个 HTML 文件，浏览器只负责渲染这些 HTML 文件。这个阶段还没有前后端的分工，通常是后端工程师顺便写了前端页面。 JSP: Java Server Page: Java服务端页面，在html页面中编写Java代码的页面 WebServer：网站服务器或web服务器 基于 AJAX 的前后端分离2005 年 AJAX 技术的正式提出，翻开了 Web 开发的新篇章。基于 AJAX，我们可以把 Web 分为前端和后端，前端负责界面和交互，后端负责业务逻辑的处理。前后端通过接口进行数据交互。我们也不再需要在各个后端语言里面写着难以维护的 HTML。网页的复杂度也由后端的 Web Server 转向了浏览器端的 JavaScript。也正因如此，开始有了前端这个职位。 基于 Node.js 的前端工程化2009年 Node.js 的出现，对于前端来说，也是一个历史性的时刻。随着 Node.js 一同出现的还有 CommonJS 规范和 npm 包管理机制。随后也出现了 Grunt、Gulp、Webpack 等一系列基于 Node.js 的前端开发构建工具。 在 2013 年前后，前端三大框架 React.js/Angular/Vue.js 相继发布第一个版本。我们可以从以往基于一个个页面的开发，变为基于一个个组件进行开发。开发完成后使用 webpack 等工具进行打包构建，并通过基于 Node.js 实现的命令行工具将构建结果发布上线。前端开发开始变得规范化、标准化、工程化。 基于 Node.js 的全栈开发Node.js 对前端的重要意义还有，以往只能运行在浏览器中的 js 也可以运行在服务器上，前端可以用自己最熟悉的语言来写服务端的代码。于是前端开始使用 Node.js 做全栈开发，开始由前端向全栈的方向转变。这是前端主动突破自己的边界。 另一方面，前端在发展，后端也在发展。也差不多在 Node.js 诞生那个时代，后端普遍开始由巨石应用模式向微服务架构转变。这也就导致以往的前后端分工出现了分歧。随着微服务架构的兴起，后端的接口渐渐变得原子性，微服务的接口也不再直接面向页面，前端的调用变得复杂了。于是 BFF（Backend For Frontend）架构出现了，在微服务和前端中间，加了一个 BFF 层，由 BFF 对接口进行聚合、裁剪后，再输出给前端。而 BFF 这层不是后端本质工作，且和前端的关系最大，所以前端自然而然选择了 Node.js 来实现。这也是当前 Node.js 在服务端较为广泛的应用的原因。 巨石应用：大部分web工程是将所有的功能模块(service side)打包到一起并放在一个web容器中运行，很多企业的Java应用程序打包为war包微服务架构：微服务架构是一种架构理念，是指将功能分解到离散的各个服务当中，从而降低系统的耦合性，并提供更加灵活的服务支持。把一个大型的单体应用程序和服务拆分为数个或数十个的微小型服务，它可扩展单个组件而不是整个的应用程序堆栈，从而满足服务等级协议。下一代前端开发模式说完了这几个阶段，可以看到，每一次前端开发模式的变化，都因某个变革性的技术而起。先是 AJAX，而后是 Node.js。那么下一个变革性的技术是什么？不言而喻，个人觉得就是 Serverless。 什么是serverless CNCF，全称Cloud Native Computing Foundation（云原生计算基金会），成立于 2015 年7月21日（于美国波特兰OSCON 2015上宣布），其最初的口号是坚持和整合开源技术来让编排容器作为微服务架构的一部分，其作为致力于云原生应用推广和普及的一支重要力量，不论您是云原生应用的开发者、管理者还是研究人员都有必要了解。 目前行业可能更多处在容器 Docker+Kubernetes, 利用 IaaS、PaaS和SaaS 来快速搭建部署应用 基础架构即服务（Infrastructure as a Service，IaaS）、平台即服务（Platform as a Service，PaaS）以及软件即服务（Software as a Service，SaaS）。 Docker是一个平台，它主要是提供一些服务，任何一台装有docker的机器你都可以建立、发布、运行你的应用程序，使用docker很省钱省时。简单的介绍Kubernetes。它就是一套成熟的商用服务编排解决方案。Kubernetes定位在Paas层，重点解决了微服务大规模部署时的服务编排问题。其实 Serverless 早已和前端产生了联系，只是我们可能没有感知。1、CDN: 相信大家都使用过 CDN，我们开发完成之后，直接将静态文件部署到 CDN 上，通过 CDN 进行内容分发、网络加速，在这个过程中，前端不需要关心 CDN 有多少个节点、如何做负载均衡，也不需要知道 CDN 的 QPS 是多少。所以从这个角度来说，CDN 是一种 serverless 的实现。 2、再比如对象存储，和 CDN 一样，我们只需要将文件上传到对象存储，就可以直接使用了，不需要关心它如何存取文件、如何进行权限控制，所以对象存储对前端来说是 Serverless。 3、甚至一些第三方的 API 服务，也是 Serverless，因为我们使用的时候，不需要去关心服务器。 当然，有了体感还不够，我们还是需要一个更精确的定义。从技术角度来说，Serverless 就是 FaaS 和 BaaS 的结合。简单来讲，FaaS（Function as a Service） 就是一些运行函数的平台，比如阿里云的函数计算、AWS 的 Lambda 等。 BaaS（Backend as a Service）则是一些后端云服务，比如云数据库、对象存储、消息队列等。利用 BaaS，可以极大简化我们的应用开发难度。 Serverless 则可以理解为运行在 FaaS 中，使用了 BaaS 的函数。 Serverless 的主要特点有：1、事件驱动—-函数在 FaaS 平台中，需要通过一系列的事件来驱动函数执行。 2、无状态—-因为每次函数执行，可能使用的都是不同的容器，无法进行内存或数据共享。如果要共享数据，则只能通过第三方服务，比如 ```Redis`` 等。 Redis（全称：Remote Dictionary Server 远程字典服务）是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value[数据库]，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。3、无运维—-使用serverless我们不需要关心服务器，也不需要关心运维，这也是serverles思想的核心； 4、低成本—-使用 Serverless 成本很低，因为我们只需要为每次函数的运行付费。函数不运行，则不花钱，也不会浪费服务器资源过度 ？？？？哪些公司平台提供这些功能???现有的服务商 云平台 亚马 二 Serverless 常见服务商提供的解决方案 1、上图是当前主要的一些 Serverless 服务，以及对应的服务解决方案。 2、从下往上，分别是基础设施、开发工具和应用场景。 亚马逊-微软-谷歌 3、基础设施主要是一些云计算厂商提供，包括云计算平台和各种 BaaS 服务，以及运行函数的 FaaS 平台。 前端主要是 Serverless 的使用者，所以对前端来说，最重要的开发工具这一层，我们需要依赖开发工具进行 Serverless 开发、调试和部署。 4、框架（Framework） 如今还没有一个统一的 Serverless 标准，不同云计算平台提供的 Serverless 服务很可能是不一样的，这就导致我们的代码，无法平滑迁移。Serverless 框架一个主要功能是简化 Serverless 开发、部署流程，另一主要功能则是屏蔽不同 Serverless 服务中的差异，让我们的函数能够在不改动或者只改动很小一部分的情况下，在其他 Serverless 服务中也能运行。常见的 Serverless 框架有 Serverless Framework、ZEIT Now、Apex 等。不过这些基本都是国外公司做的，国内还没有这样的平台。 5、Web IDE 和 Serverless 紧密相关的 Web IDE 主要也是各个云计算平台的 Web IDE。利用 Web IDE，我们可以很方便地在云端开发、调试函数，并且可以直接部署到对应的 FaaS 平台。这样的好处是避免了在本地安装各种开发工具、配置各种环境。常见的 Web IDE 有 AWS 的 Cloud9、阿里云的函数计算 Web IDE、腾讯云的 Cloud Studio。 6、当然，目前最主要的开发方式还是在本地进行开发。所以在本地开发 Serverless 的命令行工具也必不可少。 命令行工具主要有两类，一类是云计算平台提供的，如 AWS 的 aws、 Azure 的 az、阿里云的 fun；还有一类是 Serverless 框架提供的，如 serverless、now。 大部分工具如 serverless、fun 等，都是用 Node.js 语言来实现的。 7、应用场景 在开发工具上面一层，则是 Serverless 的一些垂直应用场景。除了使用传统的服务端开发，目前使用 Serverless 技术的还有小程序开发，未来可能还会涉及到物联网领域（IoT）。 不同 Serverless 服务的对比 上图从支持语言、触发器、价格等多个方面对不同 Serverless 服务进行了对比，可以发现有差异，也有共性。 1、比如几乎所有 Serverless 服务都支持 Node.js/Python/Java 等语言。 2、从支持的触发器来看，几乎所有服务也都支持 HTTP、对象存储、定时任务、消息队列等触发器。当然，这些触发器也与平台自己的后端服务相关，比如阿里云的对象存储触发器，是基于阿里云的 OSS 产品的存取等事件触发的；而 AWS 的对象存储触发器，则是基于 AWS 的 S3 的事件触发的，两个平台并不通用。这也是当前 Serverless 面临的一个问题，就是标准不统一。 S3:Amazon Simple Storage Service (Amazon S3) 是一种对象存储服务，提供行业领先的可扩展性、数据可用性、安全性和性能从计费的角度来看，各个平台的费用基本一致。在前面也提到，Serverless 的计费是按调用次数计费，执行时长。 三 基于 Serverless 的前端开发模式serverless 开发流程 1、在开始具体的案例之前，先看一下传统开发流程。 在传统开发流程中，我们需要前端写页面，后端工程师写接口。后端写完接口之后，把接口部署了，再进行前后端联调。联调完毕后再测试、上线。上线之后，还需要运维工程师对系统进行维护。整个过程涉及多个不同角色，链路较长，沟通协调也是一个问题。 2、而基于 Serverless，后端变得非常简单了，以往的后端应用被拆分为一个个函数，只需要写完函数并部署到 Serverless 服务即可，后续也不用关心任何服务器的运维操作。后端开发的门槛大幅度降低了。因此，只需要一个前端就可以完成所有的开发工作。 当然，前端基于 Serverless 去写后端，最好也需要具备一定的后端知识。涉及复杂的后端系统或者 Serverless 不适用的场景，还是需要后端开发。 serverless带来的价值1．降低运营复杂度 Serverless架构使软件应用和服务器实现了解耦，服务器不再是用户开发和运营应用的焦点。在应用上线前，用户无须再提前规划服务器的数量和规格。在运维过程中，用户无须再持续监控和维护具体服务器的状态，只需要关心应用的整体状态。应用运营的整体复杂度下降，用户的关注点可以更多地放在软件应用的体验和改进以及其他能带来更高业务价值的地方。 2．降低运营成本 服务器不再是用户关注的一个受管资源，运营的复杂度下降，应用运营所需要投入的时间和人力将大大降低。在最好的情况下，可以做到少数几个应用管理员即可管理一个处理海量请求的应用系统。 3、缩短产品的上市时间 在Serverless架构下，应用的功能被解构成若干个细颗粒度的无状态函数，功能与功能之间的边界变得更加清晰，功能模块之间的耦合度大大减小。这使得软件应用的开发效率更高，应用开发的迭代周期更短。 serverless实践基于 Serverless 的 BFF (Backend For Frontend) 传统 BFF (Backend For Frontend) 架构1、一方面，对不同的设备需要使用不同的 API，另一方面，由于微服务导致前端接口调用的复杂，所以前端开始使用 BFF 的方式，对接口进行聚合裁剪，以得到适用于前端的接口。 2、最底层的就是各种后端微服务，最上层就是各种前端应用。在微服务和应用之前，就是通常由前端开发的 BFF。 -手机端-web端-嵌入式- 这样的架构解决了接口协调的问题，但也带来了一些新的问题。 传统 BFF (Backend For Frontend) 的痛点比如针对每个设备开发一个 BFF 应用，也会面临一些重复开发的问题。而且以往前端只需要开发页面，关注于浏览器端的渲染即可，现在却需要维护各种 BFF 应用。以往前端也不需要关心并发，现在并发压力却集中到了 BFF 上。总的来说运维成本非常高，通常前端并不擅长运维。 Serverless 则可以帮我们很好的解决这些问题。用Serverless，我们可以用一个个函数来实各个接口的聚合裁剪。前端向 BFF 发起的请求，就相当于是 FaaS 的一个 HTTP 触发器，触发一个函数的执行，这个函数中来实现针对该请求的业务逻辑，比如调用多个微服务获取数据，然后再将处理结果返回给前端。这样运维的压力，就由以往的 BFF Server 转向了 FaaS 服务，前端再也不用关心服务器了。 基于 Serverless 的 BFF 架构上图则是基于 Serverless 的 BFF 架构。为了更好的管理各种 API，我们还可以添加网关层，通过网关来管理所有 API（比如阿里云的网关），比如对 API 进行分组、分环境。基于 API 网关，前端就不直接通过 HTTP 触发器来执行函数，而是将请求发送至网关，再由网关去触发具体的函数来执行。 API Gateway 在没有API网关作为统一出口的情况下，需要调用方自己组合各种服务，而且容易让调用方感知后端各种服务的存在，各个需要各个做很多相同的工作。 加入API Gateway之后的作用 一般也会把路由，安全，限流，缓存，日志，监控，重试，熔断等都放到 API 网关来做，然后服务层就完全脱离这些东西，纯粹的做业务，也能够很好的保证业务代码的干净，不用关心安全，压力等方面的问题。 基于 Serverless 的服务端渲染传统服务端渲染基于当下最流行的三大前端框架（React.js/Anguler/Vue.js），现在的渲染方式大部分都是客户端渲染。页面初始化的时候，只加载一个简单 HTML 以及对应的 JS 文件，再由 JS 来渲染出一个个页面。这种方式最主要的问题就是白屏时间和 SEO 搜索引擎优化 为了解决这个问题，前端又开始尝试服务端渲染。本质思想其实和最早的模板渲染是一样的。都是前端发起一个请求，后端 Server 解析出一个 HTML 文档，然后再返回给浏览器。只不过以往是 JSP、PHP 等服务端语言的模板，现在是基于 React、Vue 等实现的同构应用，这也是如今的服务端渲染方案的优势。 但服务端渲染又为前端带来了一些额外的问题：运维成本，前端需要维护用于渲染的服务器。 基于serverless的服务端渲染Serverless 最大的优点就是可以帮我们减少运维，那 Serverless 能不能用于服务端渲染呢？当然也是可以的。 传统的服务端渲染，每个请求的 path 都对应着服务端的每个路由，由该路由实现对应 path 的 HTML 文档渲染。用于渲染的服务端程序，就是这些集成了这些路由的应用。 使用 Serverless 来做服务端渲染，就是将以往的每个路由，都拆分为一个个函数，再在 FaaS 上部署对应的函数。这样用户请求的 path，对应的就是每个单独的函数。通过这种方式，就将运维操作转移到了 FaaS 平台，前端做服务端渲染，就不用再关心服务端程序的运维部署了。 基于 Serverless 的小程序开发1、目前国内使用 Serverless 较多的场景可能就是小程开发了。具体的实现就是小程序云开发，支付宝小程序和微信小程序都提供了云开发功能。 2、在传统的小程序开发中，我们需要前端进行小程序端的开发；后端进行服务端的开发。小程序的后端开发和其他的后端应用开发，本质是是一样的，需要关心应用的负载均衡、备份冗灾、监控报警等一些列部署运维操作。如果开发团队人很少，可能还需要前端去实现服务端。 但基于云开发，就只需要让开发者关注于业务的实现，由一个前端就能够完成整个应用的前后端开发。因为云开发将后端封装为了 BaaS 服务，并提供了对应的 SDK 给开发者，开发者可以像调用函数一样使用各种后端服务。应用的运维也转移到了提供云开发的服务商。 下面分别是使用支付宝云开发的一些例子，函数就是定义在 FaaS 服务中的函数。 负载均衡（Load Balance）其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务 备份冗灾：就是为了防止出现自然或者社会灭害带来的对存储设备的损害而造成对数据丢失,而采取的备份. 通用 Serverless 架构基于上述几个 Serverless 开发的例子，就可以总结出一个通用的 Serverless 架构。 其中最底层就是实现复杂业务的后端微服务（Backend）。然后 FaaS 层通过一系列函数实现业务逻辑，并为前端直接提供服务。对于前端开发者来说，前端可以通过编写函数的方式来实现服务端的逻辑。 同时不管是在后端、FaaS 还是前端，我们都可以去调用云计算平台提供的 BaaS 服务，大大降低开发难度、减少开发成本。小程序云开发，就是直接在前端调用 BaaS 服务的例子。 一句话总结serverless - less is more使用 Serverless，我们不需要再过多关注服务端的运维，不需要关心我们不熟悉的领域，我们只需要专注于业务的开发、专注于产品的实现。我们需要关心的事情变少了，但我们能做的事情更多了。","categories":[{"name":"架构","slug":"架构","permalink":"http://example.com/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"Serverless","slug":"Serverless","permalink":"http://example.com/tags/Serverless/"}]},{"title":"中间件","slug":"中间件","date":"2020-09-24T07:18:44.000Z","updated":"2020-09-25T01:40:52.359Z","comments":true,"path":"2020/09/24/中间件/","link":"","permalink":"http://example.com/2020/09/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/","excerpt":"","text":"中间件是什么中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。是连接两个独立应用程序或独立系统的软件。相连接的系统，即使它们具有不同的接口，但通过中间件相互之间仍能交换信息。 执行中间件的一个关键途径是信息传递。通过中间件，应用程序可以工作于多平台或 OS 环境。 中间件是介于操作系统和应用软件之间，为应用软件提供服务功能的软件，有消息中间件，交易中间件，应用服务器等。由于介于两种软件之间，所以，称为中间件。 为什么使用中间件具体地说，中间件屏蔽了底层操作系统的复杂性，使程序开发人员面对一个简单而统一的开发环境，减少程序设计的复杂性，将注意力集中在自己的业务上，不必再为程序在不同系统软件上的移植而重复工作，从而大大减少了技术上的负担。 中间件带给应用系统的，不只是开发的简便、开发周期的缩短，也减少了系统的维护、运行和管理的工作量，还减少了计算机总体费用的投入。 主要中间件的分类1. Hadoop当一个大的任务由一台机器在规定的时间内不能完成时，人们就要采用分布式计算，即很多台机器联合起来共同完成任务。换句话说，就是把大任务拆分成许多个小任务，然后再把这些小任务分配给多台计算机去完成。参与计算的多台计算机组成一个分布式系统，需要运行一系列的分布式基础算法。 Hadoop 就是一个分布式计算平台，用 Java 语言开发，包含 Common、MapReduce 和 HDFS 三个核心部件（HDFS 和 MapReduce 是最核心的两个部件）。其中： Common 为 Hadoop 的其他项目提供了一些常用工具，主要包括系统配置工具 Configuration、远程过程调用 RPC、序列化机制和 Hadoop 抽象文件系统等。 MapReduce 是处理海量数据的计算模型。 而 HDFS 用于存储海量数据，它具备高度容错性，能在低成本的通用硬件机器上稳定运行。 Hadoop 实现了分布式计算中的基础算法（如一致算法、选举算法、故障检测、快照等），同时为用户提供了编程和命令接口。程序员调用这些函数能轻松写出分布式应用程序，我们都知道，如果一切从头开始，要完成一个分布式程序的编写是异常艰难的。 Hadoop 在海量非结构化数据处理方面能充分展示它的优势，如消费者购买行为分析、商品推荐、关键词检索、信贷风险评估等。 如图 1 所示，Hadoop 其实就是一个分布式计算平台，它“覆盖”在操作系统之上，向上提供函数调用（API）和命令接口，在水平方向完成分布式系统的基础算法。作为编程人员和用户，只要了解 API 和命令即可。 图 1 Hadoop 基于 Hadoop 平台衍生出来的开源项目主要有 Yarn、HBase、Hive、ZooKeeper、Avro、Sqoop、Mahout、Crossbow 等。 以 Hadoop 为基础的生态目前已经成为大数据的标准方案，被广泛用于金融、市场、电信、交通等行业的海量数据分析，在即将到来的大数据时代，它将会发挥更大的作用。 在中国，很多行业（如银行、电信、移动、电力、石油、交通等）沉淀了大量的业务数据，对这些海量数据进行挖掘和分析，将会带来巨大的价值。 用 Hadoop 构建的应用实例对于计算资源的消耗具备两个明显的特征： 资源需求大：表明 Hadoop 需要大量的存储、计算和网络带宽。 资源需求具备季节性：表明除存储需求是经常性占用外，在运行 Mapreduce 时才需要大量的计算和网络资源，而分析大量数据的工作并不是经常性的——称为季节性 因此，云计算是大数据天生的计算资源供应途径，云计算的资源弹性很好地满足了大数据的季节性计算资源需求。也就是说，大数据是云计算经典的应用案例。当然，也可以按照大数据对计算资源的波峰需求静态配给计算资源，但是这种方案会造成资源的巨大浪费。 2. LVSLVS 是 Linux Virtual Server 的首字母缩写，意为 Linux 虚拟服务器，即把许多台物理 Linux 计算机逻辑上整合成一台超级计算机，对用户来说感觉只有一台计算能力很强的服务器，如图 2 所示。 LVS 就是一个由软件实现的负载均衡器，工作在网络 OSI 的第四层（应用层），是中国人章嵩开发的，代码已经并入了 Linux 内核。利用它，再加上一台廉价的计算机，就能构建一台企业级的负载均衡器。而那些外国大公司的负载均衡器，售价都要十几万元，甚至几十万元，便宜的也要几万元，LVS 出来后，这些产品都不得不降价。 负载均衡器的作用就是把任务分配给最合适的服务器。比如一个大型购物网店，有 100 台同样配置的服务器在运行，如果某一时刻有 10 万用户在线购物，那么通过负载均衡器，每台服务器差不多承担 1000 个在线购物用户。 LVS 的官网网站是 http：//www.linuxvirtualserver.org。另外，两个较为流行的第七层负载均衡器是 Nginx 和 HAProxy，针对应用做均衡，所以能适应的负载种类没有 LVS 多。 图 2 LVS原理图 3. Linux-HA也许有读者会问：“负载均衡器本身故障怎么办？”是的，如果负载均衡器出现故障，那么整个系统（如网店）将会瘫痪。所以人们开发了各种集群软件，如 Linux-HA 和 Keepalive 等，而微软干脆就在 Windows 服务器版中集成故障转移集群软件。 集成故障转移集群软件的核心思想是，实时检测故障机器并及时让好的机器接管工作，对外提供高可用性。Linux-HA 意为 Linux 高可用性项目，此项目具体包含如下几个组件。 名称 作用 Heartbeat 负责维护集群中各节点的信息及它们之间的心跳通信。 Pacemaker 集群资源管理器，是核心组件，客户端通过 Pacemaker 来配置、管理并监控整个集群。此组件的社区网站为 http：//clusterlabs.org/。OpenStack 高可用性部署实例中一般都采用 Pacemaker 和 HAProxy。 Resource Agent 为用于控制服务启停、监控服务状态的脚本集合，本地资源管理器（LRM）调用这些脚本来启动、停止、监控各种集群资源。 Cluster Glue 包含一套函数库和工具，在集群栈中，除集群消息传输（由 Heartbeat 承担）、集群资源管理（由 Pacemaker 承担）和资源代理（由 Resource Agent 承担）功能外，其他功能都由 Cluster Glue 来完成。它包含的两个主要部分是 LRM 和 Stonith，前者是本地资源管理器，后者的任务是隔离故障机器。 通过心跳信号（Heartbeat）检测故障，一台好的计算机会不断向其他计算机发送心跳信号，也会接收其他计算机发送过来的心跳信息。当在规定的时间内没有收到对方计算机的心跳信号时，就启动应急预案，进一步确认故障并准备接管那台计算机的任务。 例如，我们采用两台 LVS 计算机，并分别安装和配置 Linux-HA，一台 LVS 计算机作为工作机，另一台作为备份机，两台 LVS 计算机互相监督对方的运行状态。当工作机故障时，备份机接管负载均衡任务并报警。相反，当备份机出故障时，只报警，提醒技术员维修备份机。 两台LVS计算机同时出故障是比较糟糕的情况，不过这种情况发生的概率很小，除非机房断电或者遭到雷击。对于一些非常关键的应用，可以增加参与负载均衡的服务器数量来提高可靠性，如民航飞机上采用 5 台服务器。 4. 静态网站服务器我们浏览一家公司的网站时，很可能就是跟那家公司服务器上的 Apache 程序打交道，网页浏览器与 Apache 成了标准的 C/S 模式，浏览器是客户端，而 Apache 是服务端。Apache 首先把主页对应的文件 index.html 发给我们，我们看到主页内容后，点击主页上的某个链接，它又把该链接对应的文件发给我们，过程如图 3 所示。 图 3 访问静态网页的过程 配合 PHP 引擎，Apache 也支持 PHP 动态网页。过程为： 1）当 Apache 收到用户要浏览的 PHP 文件后，把这个 PHP 文件发给 PHP 执行引擎。 2）PHP 执行引擎执行该 PHP 文件，产生一个临时的静态网页文件并发回给 Apache。 3）最后 Apache 把这个临时的静态网页文件发给用户。 采用 Perl、Python 和 Ruby 脚本语言编写的动态网页，其工作过程与 PHP 类似。 Apache 是最流行的开源网站服务器，在世界排名前 100 万的网站中，有 60.6% 的网站采用 Apache；在排名前 1000 的大型网站中，Apache 占到了 34.5%，而 Ngnix 占到了 34.9%，略胜于 Apache。 5. 动态应用服务器开源的动态应用服务器有 JBoss、Tomcat、Geronimo、JOnAS，关于这些项目更详细的介绍，请参考相应的官方网站。","categories":[{"name":"架构","slug":"架构","permalink":"http://example.com/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"微服务","slug":"微服务","date":"2020-09-24T07:09:46.000Z","updated":"2020-09-25T01:40:41.037Z","comments":true,"path":"2020/09/24/微服务/","link":"","permalink":"http://example.com/2020/09/24/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"什么是微服务？为什么要用微服务？ 前言最近几年微服务很火，大家都在建设微服务，仿佛不谈点微服务相关的技术，都显得不是那么主流了。 近几年见识到身边朋友的很多公司和团队都在尝试进行微服务的改变，但很多团队并没有实际微服务踩坑经验，很多团队甚至强行为了微服务而去微服务，最终写成一个大型的分布式单体应用，就是改造后的系统既没有微服务的快速扩容，灵活发布的特性，也让原本的单体应用失去了方便开发，部署容易的特性（项目拆为多份，开发部署复杂度都提高了），不得不说是得不偿失。 作者亲身经历和参与几个大型项目微服务的改造和建设。所以想作为实践者跟大家分享关于微服务的实际经验，帮助大家了解微服务的优缺点，从而可以结合自身业务做出更加合适的选择，作为本篇文章的三个主题，例如： 什么是微服务？为什么要用微服务？ 微服务解决什么问题，又引入了什么问题？ 使用微服务应该要遵循哪些原则？什么样的情况你不应该使用微服务？ （PS：因为市面上太多对如果使用微服务框架工具的教程，所以本篇只是一篇关于微服务的总体概述性文章，不涉及各种微服务框架的安装和使用教程，我们只谈论微服务本身的设计模式的优缺点和适合应用的场景） 一：什么是微服务？为什么要用微服务？什么是微服务？（熟悉的同学可以直接跳过） 简单举例：看军事新闻的同学应该都知道，一艘航空母舰作战能力虽然很强，但是弱点太明显，就是防御能力太差，单艘的航空母舰很少单独行动，通常航空母舰战斗群才是主要军事力量，你可以把单艘航母理解为的单体应用（防御差，机动性不好），把航母战斗群（调度复杂，维护费用高）理解为微服务。 大部分的开发者经历和开发过单体应用，无论是传统的 Servlet + JSP，还是 SSM，还是现在的 SpringBoot，它们都是单体应用，那么长期陪伴我们的单体应用有什么弊端？我们是面临了什么问题，导致我们要抛弃单体应用转向微服务架构？个人总结主要问题如下： 部署成本高（无论是修改1行代码，还是10行代码，都要全量替换） 改动影响大，风险高（不论代码改动多小，成本都相同） 因为成本高，风险高，所以导致部署频率低（无法快速交付客户需求） 当然还有例如无法满足快速扩容，弹性伸缩，无法适应云环境特性等问题，但我们不一一详谈了，以上的问题，都是微服务架构要解决的问题。 二：微服务解决什么问题，又引入了什么问题？我们先看看微服务能带给我们什么？微服务架构的特点： 针对特定服务发布，影响小，风险小，成本低 频繁发布版本，快速交付需求 低成本扩容，弹性伸缩，适应云环境 我们知道一个朴素的理念，没有任何事物是完美的，任何东西都有两面性，有得必有失，那么在选择微服务在解决了快速响应和弹性伸缩的问题同时，它又给我们带来了什么问题？个人总结如下： 分布式系统的复杂性 部署，测试和监控的成本问题 分布式事务和CAP的相关问题 系统应用由原来的单体变成几十到几百个不同的工程，会所产生例如包括服务间的依赖，服务如何拆封，内部接口规范，数据传递等等问题，尤其是服务拆分，需要团队熟悉业务流程，懂得取舍，要保证拆分的粒度服务既符合“高内聚，低耦合”的基本原则，还要兼顾业务的发展以及公司的愿景，要还要说服团队成员为之努力，并且积极投入，在多方中间取得平衡。 对于分布式系统，部署，测试和监控都需要大量的中间件来支撑，而且中间件本身也要维护，原先单体应用很简单的事务问题 ，转到分布式环境就变得很复杂，分布式事务是采用简单的重试+补偿机制，还是采用二阶段提交协议等强一致性方法来解决，就要取决对业务场景的熟悉加上反复的权衡了，相同问题还包括对 CAP 模型的权衡，总之微服务对团队整体的技术栈水平整体要求更高。 三：使用微服务应该遵循哪些原则？古人云：兵马未动，粮草先行。建设微服务是需要建立长远规划，不是像写CMS那样建好数据库表，然后就开始干活，这样十有八九是会失败的。我们要进行微服务改造前，架构师要提前做好规划，我们把这里分为三步，前期阶段，设计阶段，技术阶段 前期阶段，大致要做好如下事情： 和多方充分沟通，确保能符合客户和组织的需求，并且得到认同 和团队沟通，让队友（开发/测试/运维）理解，并且积极投入 和业务部门沟通，指定版本计划和上线时间 设计阶段，参考 Sam Newman 的著作《微服务设计》，单微服务必须要满足以下的条件，才符合微服务的基本要求： 标准的 REST 风格接口（基于 HTTP 和 JSON 格式） 独立部署，避免共享数据库（避免因为数据库而影响整个分布式系统） 业务上的高内聚，减少依赖（从设计上要避免服务过大或者太小） 庞大的分布式系统，需要强大基础设施来支撑，微服务涉及哪些基础设施？ CI/CD和自动化（分布式系统几乎不可能通过人工手动发布） 虚拟化技术（要保证微服务运行环境隔离，目前行业主流的是使用 Docker 容器） 日志聚合，全链路监控（高度可观察和分析诊断问题） 说了那么多，那什么样的情况下，你的团队不适合建设微服务？（请勿对号入座） 开发团队不具备自主性，所在组织对开发团队限制非常多（具体请参考 康威定律） 团队不熟悉业务，无法识别出服务的边界，进行合理的拆分（请参考 DDD 领域驱动设计） 总结微服务设计其实是很早就有的设计思想，因为随着虚拟化技术的崛起，微服务可以低成本的实现，所以也开始流行和兴起。 微服务的内涵很深，其中就包括，自动化，去中心化，独立性等等，其中细节无法用一篇文章概述清楚，我们在做技术选型或者方案的时候，尽可能多去了解技术的本身和起源再结合我们业务的特点，进行更好的选择。","categories":[{"name":"架构","slug":"架构","permalink":"http://example.com/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://example.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"DevOps","slug":"DevOps","date":"2020-09-24T06:36:24.000Z","updated":"2020-09-24T06:42:12.699Z","comments":true,"path":"2020/09/24/DevOps/","link":"","permalink":"http://example.com/2020/09/24/DevOps/","excerpt":"","text":"DevOpsDevOps（Development+Operations）强调共同对业务目标负责，以实现用户价值作为唯一的评判标准：保证产品功能及时实现、成功部署和稳定使用； 是一种重视软件开发人员（Dev）和IT运维技术人员（Ops）之间沟通合作的文化、运动或惯例，改善团队之间的协作关系； 是一组过程、方法与系统的统称，包含开发、测试和运维； 用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合； 透过自动化“软件交付”和“架构变更”的流程，使得构建、测试、发布软件能够更加地快捷、频繁和可靠，按时交付软件产品和服务； 从定义来看，其实devops就是为了让开发、运维和QA可以高效协作的流程。（可以把DevOps看作开发、技术运营和质量保障（QA）三者的交集。） 总的说来： DevOps 是把人员、流程、产品进行结合，给用户提供持续价值的一个过程，既涉及到人员、流程、工具，也涉及到产品。 DevOps 最终目的是给客户提供持续交付的价值，流程包括：产品的规划跟踪、软件开发、构建测试、产品部署、运维、监控和优化。 通常把 DevOps 这些流程通过一个流水线的方式串联起来称为一个 DevOps 的流水线，其核心目标就是持续给用户交付有价值的产品。 简而言之，DevOps不仅涉及技术背景，还包括非技术的文化方面。在软件开发和应用周期中，提供了一个机制或模式来培育“协作”意识，帮助不同角色的成员紧密协作，充分利用现有资源，遵循交付的商业价值，共同对“输出”负责，对质量负责。 DevOps的好处与价值对于业务与产品而言，DevOps的好处更多基于持续部署与交付。从组织结构而言，DevOps是部门间沟通协作的一组流程和方法，有助于改善公司组织文化、提高员工的参与感。 代码的提交直接触发：消除等待时间，快速反馈 每个变化对应一个交付管道：使问题定位和调试变得简单 全开发流程高效自动化：稳定，快速，交付结果可预测 持续进行自动化回归测试：提升交付质量 设施共享并按需提供：资源利用最大化 可能的几个关注点DevOps绝不是推荐一定要在某一方面达到极致，而是从“整体”入手，充分激发“体系”的最佳效率。 虽然真正实现DevOps的成本高昂，但任何时候都是实现DevOps的最佳时机，因为随着业务发展，成本一定是越来越高的； 组织文化上的变革，鼓励不同的个体与部门共同协作，减少“内耗”； 合适的DevOps人员（最起码保证在“向DevOps转换阶段”中，研发人员知晓运维，运维人员了解业务）； 统一的标准、环境、工具、流程，例如：开发/测试环境尽可能地和生产环境保持一致； 自动化和持续交付，简化重复性工作和减少不必要的等待 涉及多个技术支撑：敏捷开发、持续集成&amp;部署、微服务、容器、云环境等； 个体和团队的成效都放在整个产品开发&amp;运维生命周期内来进行评价； DevOps能力环 DevOps与持续集成、持续交付DevOps的应用场景往往是一个庞大复杂的背景和流程的场景，大都包含一个持续交付流水线。 开发人员：IDE、Git等开发和编译工具 版本控制系统：分支策略、语义化版本 构建服务器：持续集成、代码质量检查 工件库：存放二进制包 系统的包管理器：编译或测试环境系统上管理二进制包 环境一致性 预发布或生产：预发布环境与生产环境互换（蓝绿发布） 发布管理：在高程度自动化测试的基础上实践自动化或半自动化（人工介入）部署 问题管理系统 。。。。。。因此，DevOps 是一个完整的面向IT运维的工作流，以 IT 自动化以及持续集成（CI）、持续部署（CD）为基础，来优化程式开发、测试、系统运维等所有环节。DevOps的技术要点由“持续集成/部署“”一线贯穿，主干开发是进行持续集成的前提，自动化以及代码周边集中管理是实施持续集成的必要条件。换而言之，DevOps 是持续集成思想的延伸，持续集成/部署是 DevOps 的技术核心，在没有自动化测试、持续集成/部署之下，DevOps就是空中楼阁。 一个完整的过程 开发团队接到任务，需要完成一个变更 为了更加顺利地开发，将这个变更分拆为几个小变更 开发人员在本地开发并且测试，如果使用了测试驱动开发，在编写功能代码之前会先编写测试，然后编写能够让测试通过的实际代码 开发人员将代码提交到企业内部的Git版本控制系统上 构建服务器获取这个变更并初始化构建流程，单元测试之后，变更可以被发布到二进制库里 配置管理系统根据“策略”，在测试环境中安装应用了新的变更 新安装触发自动化回归测试，测试成功后，质量保证团队开始做人工测试 人工测试通过后，质量保证团队将“已通过”标识给予这个变革 变更在预发布环境中进行验收测试 验收测试完成后，预发布环境被切换成生产环境，而生产环境变为新的预发布环境 典型的CICD流水线过程 项目开发编写代码，然后把代码推送到 GitLab 里存储，通过 GitLab 的 hook 使 Jenkins 执行一些 CI 的过程，比如做一些单元测试，构建 Docker image 再把这个 Docker image 调用 helm 部署到开发环境或测试环境 在测试环境里通过 Jenkins 触发一个集成测试的功能 完成后就可以把它部署到生产环境 通过 Kubernetes addon 的方式，把 Prometheus、Grafana 等监控组件部署到集群里，实现一整套从 CI 到 CD 的监控过程 DevOps黄金思维圈时刻关注正在做什么，尝试识别问题范围，找出解决方案和改善途径。Why—》How—》What Why（目的、理念）持续且快速、可靠的自动交付软件给用户： 实现价值的持续交付，赢得市场竞争 提升研发（增值活动）的时间，极大化增值活动产出 How（方法、措施） 建设自动化、可重复、可靠的持续交付流水线（IT服务供应链） 主要包括代码管理、持续集成、自动化测试、自动化部署、基础设施自动化管理等方面的工程能力 What（现象、成果） 每次代码提交都需要经过流水线验证 每次部署的版本都经过多环境验证 部署频率可以得到提升 周期时间（从代码提交到部署上线）的时间可以到分钟级 部署失败率低 部署失败的修复时间短，影响小 一些图示关系与演进 涉及的工具DevOps的目标不是单靠一款工具就能实现的。在各个阶段，每个都有其单独对应的目标。依赖于组织的选择，有着各种各样的工具可以在相应的背景和趋势下，实现当前业务目标，满足中远期的需求。 DevOps对应用程序发布的影响 在很多企业中，应用程序发布是一项涉及多个团队、压力很大、风险很高的活动。然而在具备DevOps能力的组织中，应用程序发布的风险很低，原因如下 [2] ： （1）减少变更范围 与传统的瀑布模式模型相比，采用敏捷或迭代式开发意味着更频繁的发布、每次发布包含的变化更少。由于部署经常进行，因此每次部署不会对生产系统造成巨大影响，应用程序会以平滑的速率逐渐生长。 （2）加强发布协调 靠强有力的发布协调人来弥合开发与运营之间的技能鸿沟和沟通鸿沟；采用电子数据表、电话会议和企业门户（wiki、sharepoint）等协作工具来确保所有相关人员理解变更的内容并全力合作。 （3）自动化 强大的部署自动化手段确保部署任务的可重复性、减少部署出错的可能性。 与传统开发方法那种大规模的、不频繁的发布（通常以“季度”或“年”为单位）相比，敏捷方法大大提升了发布频率（通常以“天”或“周”为单位）。 实现DevOps需要什么？ 硬性要求：工具上的准备 上文提到了工具链的打通，那么工具自然就需要做好准备。现将工具类型及对应的不完全列举整理如下： 代码管理（SCM）：GitHub、GitLab、BitBucket、SubVersion 构建工具：Ant、Gradle、maven 自动部署：Capistrano、CodeDeploy 持续集成（CI）：Bamboo、Hudson、Jenkins 配置管理：Ansible、Chef、Puppet、SaltStack、ScriptRock GuardRail 容器：Docker、LXC、第三方厂商如AWS 编排：Kubernetes、Core、Apache Mesos、DC/OS 服务注册与发现：Zookeeper、etcd、Consul 脚本语言：python、ruby、shell 日志管理：ELK、Logentries 系统监控：Datadog、Graphite、Icinga、Nagios 性能监控：AppDynamics、New Relic、Splunk 压力测试：JMeter、Blaze Meter、loader.io 预警：PagerDuty、pingdom、厂商自带如AWS SNS HTTP加速器：Varnish 消息总线：ActiveMQ、SQS 应用服务器：Tomcat、JBoss Web服务器：Apache、Nginx、IIS 数据库：MySQL、Oracle、PostgreSQL等关系型数据库；cassandra、mongoDB、redis等NoSQL数据库 项目管理（PM）：Jira、Asana、Taiga、Trello、Basecamp、Pivotal Tracker 在工具的选择上，需要结合公司业务需求和技术团队情况而定。（注：更多关于工具的详细介绍可以参见此文：51 Best DevOps Tools for #DevOps Engineers） 软性需求：文化和人 DevOps成功与否，公司组织是否利于协作是关键。开发人员和运维人员可以良好沟通互相学习，从而拥有高生产力。并且协作也存在于业务人员与开发人员之间。","categories":[{"name":"敏捷开发","slug":"敏捷开发","permalink":"http://example.com/categories/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://example.com/tags/DevOps/"}]},{"title":"Nginx功能及配置","slug":"Nginx功能及配置","date":"2020-09-21T05:09:32.000Z","updated":"2020-09-21T05:10:54.482Z","comments":true,"path":"2020/09/21/Nginx功能及配置/","link":"","permalink":"http://example.com/2020/09/21/Nginx%E5%8A%9F%E8%83%BD%E5%8F%8A%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Nginx功能概述HTTP基础功能： 处理静态文件，索引文件以及自动索引； 反向代理加速(无缓存)，简单的负载均衡和容错； FastCGI，简单的负载均衡和容错； 模块化的结构。过滤器包括gzipping, byte ranges, chunked responses, 以及 SSI-filter 。在SSI过滤器中，到同一个 proxy 或者 FastCGI 的多个子请求并发处理； SSL 和 TLS SNI 支持； IMAP/POP3 代理服务功能： 使用外部 HTTP 认证服务器重定向用户到 IMAP/POP3 后端； 使用外部 HTTP 认证服务器认证用户后连接重定向到内部的 SMTP 后端； 认证方法： POP3: POP3 USER/PASS, APOP, AUTH LOGIN PLAIN CRAM-MD5; IMAP: IMAP LOGIN; SMTP: AUTH LOGIN PLAIN CRAM-MD5; SSL 支持； 在 IMAP 和 POP3 模式下的 STARTTLS 和 STLS 支持； 支持的操作系统： FreeBSD 3.x, 4.x, 5.x, 6.x i386; FreeBSD 5.x, 6.x amd64; Linux 2.2, 2.4, 2.6 i386; Linux 2.6 amd64; Solaris 8 i386; Solaris 9 i386 and sun4u; Solaris 10 i386; MacOS X (10.4) PPC; 结构与扩展： 一个主进程和多个工作进程。工作进程是单线程的，且不需要特殊授权即可运行； kqueue (FreeBSD 4.1+), epoll (Linux 2.6+), rt signals (Linux 2.2.19+), /dev/poll (Solaris 7 11/99+), select, 以及 poll 支持； kqueue支持的不同功能包括 EV_CLEAR, EV_DISABLE （临时禁止事件）， NOTE_LOWAT, EV_EOF, 有效数据的数目，错误代码； sendfile (FreeBSD 3.1+), sendfile (Linux 2.2+), sendfile64 (Linux 2.4.21+), 和 sendfilev (Solaris 8 7/01+) 支持； 输入过滤 (FreeBSD 4.1+) 以及 TCP_DEFER_ACCEPT (Linux 2.4+) 支持； 10,000 非活动的 HTTP keep-alive 连接仅需要 2.5M 内存。 最小化的数据拷贝操作； 其他HTTP功能： 基于IP 和名称的虚拟主机服务； Memcached 的 GET 接口； 支持 keep-alive 和管道连接； 灵活简单的配置； 重新配置和在线升级而无须中断客户的工作进程； 可定制的访问日志，日志写入缓存，以及快捷的日志回卷； 4xx-5xx 错误代码重定向； 基于 PCRE 的 rewrite 重写模块； 基于客户端 IP 地址和 HTTP 基本认证的访问控制； PUT, DELETE, 和 MKCOL 方法； 支持 FLV （Flash 视频）； 带宽限制； 实验特性： 内嵌的perl 通过aio_read() / aio_write()的套接字工作的实验模块，仅在 FreeBSD 下。 对线程的实验化支持，FreeBSD 4.x 的实现基于 rfork() Nginx 主要的英语站点是 http://sysoev.ru/en/ 英语文档草稿由 Aleksandar Lazic 完成 点击 。 Nginx安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164nginx可以使用各平台的默认包来安装，本文是介绍使用源码编译安装，包括具体的编译参数信息。正式开始前，编译环境gcc g++ 开发库之类的需要提前装好，这里默认你已经装好。ububtu平台编译环境可以使用以下指令apt-get install build-essentialapt-get install libtoolcentos平台编译环境使用如下指令安装make：yum -y install gcc automake autoconf libtool make安装g++:yum install gcc gcc-c++下面正式开始---------------------------------------------------------------------------一般我们都需要先装pcre, zlib，前者为了重写rewrite，后者为了gzip压缩。1.选定源码目录可以是任何目录，本文选定的是/usr/local/srccd /usr/local/src2.安装PCRE库https://ftp.pcre.org/pub/pcre/ 下载最新的 PCRE 源码包，使用下面命令下载编译和安装 PCRE 包：cd /usr/local/srcwget https://ftp.pcre.org/pub/pcre/pcre-8.44.tar.gz tar -zxvf pcre-8.44.tar.gzcd pcre-8.44./configuremakemake install3.安装zlib库http://zlib.net/zlib-1.2.11.tar.gz 下载最新的 zlib 源码包，使用下面命令下载编译和安装 zlib包：cd /usr/local/srcwget http://zlib.net/zlib-1.2.11.tar.gztar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11./configuremakemake install4.安装ssl（某些vps默认没装ssl)cd /usr/local/srcwget https://www.openssl.org/source/openssl-1.1.1g.tar.gztar -zxvf openssl-1.1.1g.tar.gz5.安装nginxNginx 一般有两个版本，分别是稳定版和开发版，您可以根据您的目的来选择这两个版本的其中一个，下面是把 Nginx 安装到 /usr/local/nginx 目录下的详细步骤：cd /usr/local/srcwget http://nginx.org/download/nginx-1.18.0.tar.gztar -zxvf nginx-1.18.0.tar.gzcd nginx-1.18.0 ./configure --sbin-path=/usr/local/nginx/nginx \\--conf-path=/usr/local/nginx/nginx.conf \\--pid-path=/usr/local/nginx/nginx.pid \\--with-http_gzip_static_module \\--with-http_stub_status_module \\--with-file-aio \\--with-http_realip_module \\--with-http_ssl_module \\--with-pcre=/usr/local/src/pcre-8.44 \\--with-zlib=/usr/local/src/zlib-1.2.11 \\--with-openssl=/usr/local/src/openssl-1.1.1g make -j2make install--with-pcre=/usr/local/src/pcre-8.44 指的是pcre-8.44 的源码路径。--with-zlib=/usr/local/src/zlib-1.2.11指的是zlib-1.2.11 的源码路径。安装成功后 /usr/local/nginx 目录下如下fastcgi.conf koi-win nginx.conf.defaultfastcgi.conf.default logs scgi_paramsfastcgi_params mime.types scgi_params.defaultfastcgi_params.default mime.types.default uwsgi_paramshtml nginx uwsgi_params.defaultkoi-utf nginx.conf win-utf6.启动确保系统的 80 端口没被其他程序占用，运行/usr/local/nginx/nginx 命令来启动 Nginx，netstat -ano|grep 80如果查不到结果后执行，有结果则忽略此步骤（ubuntu下必须用sudo启动，不然只能在前台运行）sudo /usr/local/nginx/nginx打开浏览器访问此机器的 IP，如果浏览器出现 Welcome to nginx! 则表示 Nginx 已经安装并运行成功。![nginx](nginx11.png)-----------------------------------------------------到这里nginx就安装完成了，如果只是处理静态html就不用继续安装了如果你需要处理php脚本的话，还需要安装php-fpm。下面安装排错附：可能遇到的错误和一些帮助信息1.1编译pcre错误libtool: compile: unrecognized option `-DHAVE_CONFIG_H&#x27;libtool: compile: Try `libtool --help&#x27; for more information.make[1]: *** [pcrecpp.lo] Error 1make[1]: Leaving directory `/usr/local/src/pcre-8.34&#x27;make: *** [all] Error 2![nginx](nginx22.png)解决办法：安装g++,别忘了重新configureapt-get install g++apt-get install build-essentialmake clean./configuremake1.2 make出错make: *** No rule to make target `build&#x27;, needed by `default&#x27;. Stop../configure: error: SSL modules require the OpenSSL library.You can either do not enable the modules, or install the OpenSSL libraryinto the system, or build the OpenSSL library statically from the sourcewith nginx by using --with-openssl= option.按照第4步的安装方法或ubuntu下apt-get install opensslapt-get install libssl-devcentos下yum -y install openssl openssl-devel2.nginx编译选项make是用来编译的，它从Makefile中读取指令，然后编译。make install是用来安装的，它也从Makefile中读取指令，安装到指定的位置。configure命令是用来检测你的安装平台的目标特征的。它定义了系统的各个方面，包括nginx的被允许使用的连接处理的方法，比如它会检测你是不是有CC或GCC，并不是需要CC或GCC，它是个shell脚本，执行结束时，它会创建一个Makefile文件。nginx的configure命令支持以下参数：--prefix=path 定义一个目录，存放服务器上的文件 ，也就是nginx的安装目录。默认使用 /usr/local/nginx。--sbin-path=path 设置nginx的可执行文件的路径，默认为 prefix/sbin/nginx.--conf-path=path 设置在nginx.conf配置文件的路径。nginx允许使用不同的配置文件启动，通过命令行中的-c选项。默认为prefix/conf/nginx.conf.--pid-path=path 设置nginx.pid文件，将存储的主进程的进程号。安装完成后，可以随时改变的文件名 ， 在nginx.conf配置文件中使用 PID指令。默认情况下，文件名 为prefix/logs/nginx.pid.--error-log-path=path 设置主错误，警告，和诊断文件的名称。安装完成后，可以随时改变的文件名 ，在nginx.conf配置文件中 使用 的error_log指令。默认情况下，文件名 为prefix/logs/error.log.--http-log-path=path 设置主请求的HTTP服务器的日志文件的名称。安装完成后，可以随时改变的文件名 ，在nginx.conf配置文件中 使用 的access_log指令。默认情况下，文件名 为prefix/logs/access.log.--user=name 设置nginx工作进程的用户。安装完成后，可以随时更改的名称在nginx.conf配置文件中 使用的 user指令。默认的用户名是nobody。--group=name 设置nginx工作进程的用户组。安装完成后，可以随时更改的名称在nginx.conf配置文件中 使用的 user指令。默认的为非特权用户。--with-select_module --without-select_module 启用或禁用构建一个模块来允许服务器使用select()方法。该模块将自动建立，如果平台不支持的kqueue，epoll，rtsig或/dev/poll。--with-poll_module --without-poll_module 启用或禁用构建一个模块来允许服务器使用poll()方法。该模块将自动建立，如果平台不支持的kqueue，epoll，rtsig或/dev/poll。--without-http_gzip_module — 不编译压缩的HTTP服务器的响应模块。编译并运行此模块需要zlib库。--without-http_rewrite_module 不编译重写模块。编译并运行此模块需要PCRE库支持。--without-http_proxy_module — 不编译http_proxy模块。--with-http_ssl_module — 使用https协议模块。默认情况下，该模块没有被构建。建立并运行此模块的OpenSSL库是必需的。--with-pcre=path — 设置PCRE库的源码路径。PCRE库的源码（版本4.4 - 8.30）需要从PCRE网站下载并解压。其余的工作是Nginx的./ configure和make来完成。正则表达式使用在location指令和 ngx_http_rewrite_module 模块中。--with-pcre-jit —编译PCRE包含“just-in-time compilation”（1.1.12中， pcre_jit指令）。--with-zlib=path —设置的zlib库的源码路径。要下载从 zlib（版本1.1.3 - 1.2.5）的并解压。其余的工作是Nginx的./ configure和make完成。ngx_http_gzip_module模块需要使用zlib 。--with-cc-opt=parameters — 设置额外的参数将被添加到CFLAGS变量。例如,当你在FreeBSD上使用PCRE库时需要使用:--with-cc-opt=&quot;-I /usr/local/include。.如需要需要增加 select()支持的文件数量:--with-cc-opt=&quot;-D FD_SETSIZE=2048&quot;.--with-ld-opt=parameters —设置附加的参数，将用于在链接期间。例如，当在FreeBSD下使用该系统的PCRE库,应指定:--with-ld-opt=&quot;-L /usr/local/lib&quot;.典型实例(下面为了展示需要写在多行，执行时内容需要在同一行)./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module --with-pcre=../pcre-4.4 --with-zlib=../zlib-1.1.3 nginx基本配置与参数说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124#运行用户user nobody;#启动进程,通常设置成和cpu的数量相等worker_processes 1;#全局错误日志及PID文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;#工作模式及连接数上限events &#123; #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 # ulimit -SHn 65535&#125;http &#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6].&quot;; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k; #设定虚拟主机配置 server &#123; #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; #默认请求 location / &#123; #定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125; #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ .php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; #禁止访问 .htxxx 文件 location ~ /.ht &#123; deny all; &#125; &#125;&#125; 运行和控制nginx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200nginx命令行参数不像许多其他软件系统，Nginx 仅有几个命令行参数，完全通过配置文件来配置-c &lt;/path/to/config&gt; 为 Nginx 指定一个配置文件，来代替缺省的。-t 不运行，而仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件。-v 显示 nginx 的版本。-V 显示 nginx 的版本，编译器版本和配置参数。 nginx控制信号可以使用信号系统来控制主进程。默认，nginx 将其主进程的 pid 写入到 /usr/local/nginx/nginx.pid 文件中。通过传递参数给 ./configure 或使用 pid 指令，来改变该文件的位置。主进程可以处理以下的信号：TERM, INT 快速关闭QUIT 从容关闭HUP 重载配置用新的配置开始新的工作进程从容关闭旧的工作进程USR1 重新打开日志文件USR2 平滑升级可执行程序。WINCH 从容关闭工作进程尽管你不必自己操作工作进程，但是，它们也支持一些信号：TERM, INT 快速关闭QUIT 从容关闭USR1 重新打开日志文件 nginx 启动、停止、重启命令nginx启动sudo /usr/local/nginx/nginx (nginx二进制文件绝对路径，可以根据自己安装路径实际决定) nginx从容停止命令，等所有请求结束后关闭服务ps -ef |grep nginxkill -QUIT nginx主进程号 nginx 快速停止命令，立刻关闭nginx进程ps -ef |grep nginxkill -TERM nginx主进程号 如果以上命令不管用，可以强制停止kill -9 nginx主进程号 如果嫌麻烦可以不用查看进程号，直接使用命令进行操作其中/usr/local/nginx/nginx.pid 为nginx.conf中pid命令设置的参数，用来存放nginx主进程号的文件kill -信号类型(HUP|TERM|QUIT) cat /usr/local/nginx/nginx.pid例如kill -QUIT `cat /usr/local/nginx/nginx.pid`1kill -QUIT `cat /usr/local/nginx/nginx.pid`nginx重启命令nginx重启可以分成几种类型1.简单型，先关闭进程，修改你的配置后，重启进程。kill -QUIT cat /usr/local/nginx/nginx.pidsudo /usr/local/nginx/nginx2.重新加载配置文件，不重启进程，不会停止处理请求3.平滑更新nginx二进制，不会停止处理请求 使用信号加载新的配置Nginx 支持几个信号，能在它运行时控制其操作。其中最普通的是 15 ，用来中止运行的进程：# &lt;strong&gt;ps aux | egrep &#x27;(PID|nginx)&#x27;&lt;/strong&gt;USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 2213 0.0 0.0 6784 2036 ? Ss 03:01 0:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf# &lt;strong&gt;kill -15 2213&lt;/strong&gt;# &lt;strong&gt;ps aux | egrep &#x27;(PID|nginx)&#x27;&lt;/strong&gt;USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 2213 0.0 0.0 6784 2036 ? Ss 03:01 0:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf# &lt;strong&gt;kill -15 2213&lt;/strong&gt;而最有趣的是能平滑改变 nginx 配置的选项（请注意，在重载前，要先测试一下配置文件）： #&lt;strong&gt; nginx -t -c /etc/nginx/nginx.conf&lt;/strong&gt;2006/09/16 13:07:10 [info] 15686#0: the configuration file /etc/nginx/nginx.conf syntax is ok2006/09/16 13:07:10 [info] 15686#0: the configuration file /etc/nginx/nginx.conf was tested successfully#&lt;strong&gt; ps aux | egrep &#x27;(PID|nginx)&#x27;&lt;/strong&gt;USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 2213 0.0 0.0 6784 2036 ? Ss 03:01 0:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf&lt;strong&gt;# kill -HUP 2213&lt;/strong&gt;#&lt;strong&gt; nginx -t -c /etc/nginx/nginx.conf&lt;/strong&gt;2006/09/16 13:07:10 [info] 15686#0: the configuration file /etc/nginx/nginx.conf syntax is ok2006/09/16 13:07:10 [info] 15686#0: the configuration file /etc/nginx/nginx.conf was tested successfully#&lt;strong&gt; ps aux | egrep &#x27;(PID|nginx)&#x27;&lt;/strong&gt;USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 2213 0.0 0.0 6784 2036 ? Ss 03:01 0:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf&lt;strong&gt;# kill -HUP 2213&lt;/strong&gt;当 nginx 接收到 HUP 信号，它会尝试先解析配置文件（如果指定配置文件，就使用指定的，否则使用默认的），成功的话，就应用新的配置文件（例如：重新打开日志文件或监听的套接 字）。之后，nginx 运行新的工作进程并从容关闭旧的工作进程。通知工作进程关闭监听套接字但是继续为当前连接的客户提供服务。所有客户端的服务完成后，旧的工作进程被关闭。 如果新的配置文件应用失败，nginx 将继续使用旧的配置进行工作。 平滑升级到新的二进制代码你可以在不中断服务的情况下 - 新的请求也不会丢失，使用新的 nginx 可执行程序替换旧的（当升级新版本或添加/删除服务器模块时）。首先，使用新的可执行程序替换旧的（最好做好备份），然后，发送 USR2 (kill -USR2 pid)信号给主进程。主进程将重命名它的 .pid 文件为 .oldbin (比如：/usr/local/nginx/logs/nginx.pid.oldbin)，然后执行新的可执行程序，依次启动新的主进程和新的工作进程： PID PPID USER %CPU VSZ WCHAN COMMAND33126 1 root 0.0 1164 pause nginx: master process /usr/local/nginx/sbin/nginx33134 33126 nobody 0.0 1368 kqread nginx: worker process (nginx)33135 33126 nobody 0.0 1380 kqread nginx: worker process (nginx)33136 33126 nobody 0.0 1368 kqread nginx: worker process (nginx)36264 33126 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) PID PPID USER %CPU VSZ WCHAN COMMAND33126 1 root 0.0 1164 pause nginx: master process /usr/local/nginx/sbin/nginx33134 33126 nobody 0.0 1368 kqread nginx: worker process (nginx)33135 33126 nobody 0.0 1380 kqread nginx: worker process (nginx)33136 33126 nobody 0.0 1368 kqread nginx: worker process (nginx)36264 33126 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)在这时，两个 nginx 实例会同时运行，一起处理输入的请求。要逐步停止旧的实例，你必须发送 WINCH 信号给旧的主进程，然后，它的工作进程就将开始从容关闭： PID PPID USER %CPU VSZ WCHAN COMMAND33126 1 root 0.0 1164 pause nginx: master process /usr/local/nginx/sbin/nginx33135 33126 nobody 0.0 1380 kqread nginx: worker process is shutting down (nginx)36264 33126 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) PID PPID USER %CPU VSZ WCHAN COMMAND33126 1 root 0.0 1164 pause nginx: master process /usr/local/nginx/sbin/nginx33135 33126 nobody 0.0 1380 kqread nginx: worker process is shutting down (nginx)36264 33126 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)一段时间后，旧的工作进程处理了所有已连接的请求后退出，就仅由新的工作进程来处理输入的请求了： PID PPID USER %CPU VSZ WCHAN COMMAND33126 1 root 0.0 1164 pause nginx: master process /usr/local/nginx/sbin/nginx36264 33126 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) PID PPID USER %CPU VSZ WCHAN COMMAND33126 1 root 0.0 1164 pause nginx: master process /usr/local/nginx/sbin/nginx36264 33126 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx)这时，因为旧的服务器还尚未关闭它监听的套接字，所以，通过下面的几步，你仍可以恢复旧的服务器：发送 HUP 信号给旧的主进程 - 它将在不重载配置文件的情况下启动它的工作进程发送 QUIT 信号给新的主进程，要求其从容关闭其工作进程发送 TERM 信号给新的主进程，迫使其退出如果因为某些原因新的工作进程不能退出，向其发送 KILL 信号新的主进程退出后，旧的主进程会由移除 .oldbin 前缀，恢复为它的 .pid 文件，这样，一切就都恢复到升级之前了。如果尝试升级成功，而你也希望保留新的服务器时，发送 QUIT 信号给旧的主进程使其退出而只留下新的服务器运行： PID PPID USER %CPU VSZ WCHAN COMMAND 36264 1 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx 36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) 36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) 36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) PID PPID USER %CPU VSZ WCHAN COMMAND 36264 1 root 0.0 1148 pause nginx: master process /usr/local/nginx/sbin/nginx 36265 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) 36266 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) 36267 36264 nobody 0.0 1364 kqread nginx: worker process (nginx) nginx反向代理配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657nginx作为web服务器一个重要的功能就是反向代理。当然你也可以使用nginx配置正向代理，本是介绍如何配置nginx的反向代理。nginx反向代理的指令不需要新增额外的模块，默认自带proxy_pass指令，只需要修改配置文件就可以实现反向代理。什么是反向代理服务器反向代理功能是nginx的三大主要功能之一（静态web服务器、反向代理、负载均衡）。nginx一般同时做为静态web服务器和反向代理服务器，做为web服务器访问静态文件图片、css、js、html等文件，做为反向代理服务器把请求发给后端业务处理服务，如果有多个后端处理节点，会配置负载均衡功能。反向代理服务器是一种代理服务器，用于管理从外部网络到内部网络的连接或任何特定请求。它保护、路由和管理从外部网络到内部网络、Web服务器或专用网络的流量。![nginx](nginx33.png)外网客户机：我们平时打开浏览器输入网址访问www.nginx.cn的场景中，我们的笔记本就可以理解为一个外网客户机。nginx反向代理服务：浏览器输入网址并回车后，会发起一个http请求给nginx（反向代理服务器），这个请求如果是访问静态文件，那么nginx作为web服务器直接返回请求的内容，如果是访问的后台服务逻辑，那么nginx把请求转发给后端的服务处理。内网web服务：后端的服务可以是很多种类型，LNMP环境下的php-fpm进程，Java环境下的tomcat、jetty等容器，通过程序逻辑处理http请求，生成html页面或者json串返回给客户端。对于小型应用，后端服务可以和nginx部署在同一台机器上。反向代理服务器的好处nginx反向代理重要的作用是配合upstream实现负载均衡。同时增加安全性，客户端不能直接访问后端服务，多了一个中间的屏障。提升性能，通过异步非阻塞的方式把请求传给后端，提升了并发处理能力。也可利用缓存、压缩响应提高响应速度。nginx如何配置反向代理nginx反向代理不需要编译额外的模块，默认自带proxy_pass和fastcgi_pass指令，通过在location配置块中增加指令就可以实现反向代理功能。以www.nginx.cn为例，这个网站用的wordpress程序，wordpress是php语言编写，那么需要通过php运行环境，可以选择apache的php扩展或者php-fpm环境，主流的选择是php-fpm，php-fpm设置为Unix socket模式或者ip:端口模式 。Unix socket后端服务配置server &#123; listen 80; server_name www.nginx.cn nginx.cn; location /app &#123; fastcgi_pass unix:/tmp/php-cgi.sock; &#125;&#125;ip端口后端服务配置server &#123; listen 80; server_name www.nginx.cn nginx.cn; location /app &#123; proxy_pass http://127.0.0.1:8080; &#125;&#125;proxy_pass和fastcgi_pass区别对于上面介绍的两种情况下proxy_pass和fastcgi_pass可以互相替代使用，不过两者还是有区别的，从名字我们就可以看出来，fastcgi_pass是用来反向代理fastcgi协议，proxy_pass可以代理包括fastcgi协议在内的其它协议。例如镜像一个网站，这种情况下就需要proxy_pass：location /&#123; proxy_pass http://www.baidu.com;&#125; nginx location匹配规则12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758location匹配命令~ #波浪线表示执行一个正则匹配，区分大小写~* #表示执行一个正则匹配，不区分大小写^~ #^~表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录= #进行普通字符精确匹配@ #&quot;@&quot; 定义一个命名的 location，使用在内部定向时，例如 error_page, try_fileslocation 匹配的优先级(与location在配置文件中的顺序无关)= 精确匹配会第一个被处理。如果发现精确匹配，nginx停止搜索其他匹配。普通字符匹配，正则表达式规则和长的块规则将被优先和查询匹配，也就是说如果该项匹配还需去看有没有正则表达式匹配和更长的匹配。^~ 则只匹配该规则，nginx停止搜索其他匹配，否则nginx会继续处理其他location指令。最后匹配理带有&quot;~&quot;和&quot;~*&quot;的指令，如果找到相应的匹配，则nginx停止搜索其他匹配；当没有正则表达式或者没有正则表达式被匹配的情况下，那么匹配程度最高的逐字匹配指令会被使用。location 优先级官方文档Directives with the = prefix that match the query exactly. If found, searching stops.All remaining directives with conventional strings, longest match first. If this match used the ^~ prefix, searching stops.Regular expressions, in order of definition in the configuration file.If #3 yielded a match, that result is used. Else the match from #2 is used.=前缀的指令严格匹配这个查询。如果找到，停止搜索。所有剩下的常规字符串，最长的匹配。如果这个匹配使用^〜前缀，搜索停止。正则表达式，在配置文件中定义的顺序。如果第3条规则产生匹配的话，结果被使用。否则，使用第2条规则的结果。 例如location = / &#123; # 只匹配&quot;/&quot;. [ configuration A ] &#125;location / &#123; # 匹配任何请求，因为所有请求都是以&quot;/&quot;开始 # 但是更长字符匹配或者正则表达式匹配会优先匹配 [ configuration B ] &#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开始的请求，并停止匹配 其它location [ configuration C ] &#125;location ~* .(gif|jpg|jpeg)$ &#123; # 匹配以 gif, jpg, or jpeg结尾的请求. # 但是所有 /images/ 目录的请求将由 [Configuration C]处理. [ configuration D ] &#125;请求URI例子:/ -&gt; 符合configuration A/documents/document.html -&gt; 符合configuration B/images/1.gif -&gt; 符合configuration C/documents/1.jpg -&gt;符合 configuration D@location 例子error_page 404 = @fetch;location @fetch(proxy_pass http://fetch;) nginx upstream 配置和作用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152配置例子upstream backend &#123; server backend1.example.com weight=5; server backend2.example.com:8080; server unix:/tmp/backend3; server backup1.example.com:8080 backup; server backup2.example.com:8080 backup;&#125;server &#123; location / &#123; proxy_pass http://backend; &#125;&#125;指令语法: upstream name &#123; ... &#125;默认值: —上下文: http定义一组服务器。 这些服务器可以监听不同的端口。 而且，监听在TCP和UNIX域套接字的服务器可以混用。例子：upstream backend &#123; server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3;&#125;默认情况下，nginx按加权轮转的方式将请求分发到各服务器。 在上面的例子中，每7个请求会通过以下方式分发： 5个请求分到backend1.example.com， 一个请求分到第二个服务器，一个请求分到第三个服务器。 与服务器通信的时候，如果出现错误，请求会被传给下一个服务器，直到所有可用的服务器都被尝试过。 如果所有服务器都返回失败，客户端将会得到最后通信的那个服务器的（失败）响应结果。语法: server address [parameters];默认值: —上下文: upstream定义服务器的地址address和其他参数parameters。 地址可以是域名或者IP地址，端口是可选的，或者是指定“unix:”前缀的UNIX域套接字的路径。如果没有指定端口，就使用80端口。 如果一个域名解析到多个IP，本质上是定义了多个server。你可以定义下面的参数：weight=number设定服务器的权重，默认是1。max_fails=number设定Nginx与服务器通信的尝试失败的次数。在fail_timeout参数定义的时间段内，如果失败的次数达到此值，Nginx就认为服务器不可用。在下一个fail_timeout时间段，服务器不会再被尝试。 失败的尝试次数默认是1。设为0就会停止统计尝试次数，认为服务器是一直可用的。 你可以通过指令proxy_next_upstream、 fastcgi_next_upstream和memcached_next_upstream来配置什么是失败的尝试。 默认配置时，http_404状态不被认为是失败的尝试。fail_timeout=time设定统计失败尝试次数的时间段。在这段时间中，服务器失败次数达到指定的尝试次数，服务器就被认为不可用。服务器被认为不可用的时间段。默认情况下，该超时时间是10秒。backup标记为备用服务器。当主服务器不可用以后，请求会被传给这些服务器。down标记服务器永久不可用，可以跟ip_hash指令一起使用。Example:upstream backend &#123; server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; server backup1.example.com:8080 backup;&#125;语法: ip_hash;默认值: —上下文: upstream指定服务器组的负载均衡方法，请求基于客户端的IP地址在服务器间进行分发。 IPv4地址的前三个字节或者IPv6的整个地址，会被用来作为一个散列key。 这种方法可以确保从同一个客户端过来的请求，会被传给同一台服务器。除了当服务器被认为不可用的时候，这些客户端的请求会被传给其他服务器，而且很有可能也是同一台服务器。从1.3.2和1.2.2版本开始支持IPv6地址。如果其中一个服务器想暂时移除，应该加上down参数。这样可以保留当前客户端IP地址散列分布。例子：upstream backend &#123; ip_hash; server backend1.example.com; server backend2.example.com; server backend3.example.com down; server backend4.example.com;&#125;从1.3.1和1.2.2版本开始，ip_hash的负载均衡方法才支持设置服务器权重值。语法: keepalive connections;默认值: —上下文: upstream这个指令出现在版本 1.1.4.激活对上游服务器的连接进行缓存。connections参数设置每个worker进程与后端服务器保持连接的最大数量。这些保持的连接会被放入缓存。 如果连接数大于这个值时，最久未使用的连接会被关闭。需要注意的是，keepalive指令不会限制Nginx进程与上游服务器的连接总数。 新的连接总会按需被创建。 connections参数应该稍微设低一点，以便上游服务器也能处理额外新进来的连接。配置memcached上游服务器连接keepalive的例子：upstream memcached_backend &#123; server 127.0.0.1:11211; server 10.0.0.2:11211; keepalive 32;&#125;server &#123; ... location /memcached/ &#123; set $memcached_key $uri; memcached_pass memcached_backend; &#125;&#125;对于HTTP代理，proxy_http_version指令应该设置为“1.1”，同时“Connection”头的值也应被清空。upstream http_backend &#123; server 127.0.0.1:8080; keepalive 16;&#125;server &#123; ... location /http/ &#123; proxy_pass http://http_backend; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; ... &#125;&#125;另外一种选择是，HTTP/1.0协议的持久连接也可以通过发送“Connection: Keep-Alive”头来实现。不过不建议这样用。对于FastCGI的服务器，需要设置 fastcgi_keep_conn 指令来让连接keepalive工作：upstream fastcgi_backend &#123; server 127.0.0.1:9000; keepalive 8;&#125;server &#123; ... location /fastcgi/ &#123; fastcgi_pass fastcgi_backend; fastcgi_keep_conn on; ... &#125;&#125;当使用的负载均衡方法不是默认的轮转法时，必须在keepalive 指令之前配置。针对SCGI和uwsgi协议，还没有实现其keepalive连接的打算。语法: least_conn;默认值: —上下文: upstream这个指令出现在版本 1.3.1 和 1.2.2.指定服务器组的负载均衡方法，根据其权重值，将请求发送到活跃连接数最少的那台服务器。 如果这样的服务器有多台，那就采取有权重的轮转法进行尝试。嵌入的变量ngx_http_upstream_module模块支持以下嵌入变量：$upstream_addr保存服务器的IP地址和端口或者是UNIX域套接字的路径。 在请求处理过程中，如果有多台服务器被尝试了，它们的地址会被拼接起来，以逗号隔开，比如： “192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock”。 如果在服务器之间通过“X-Accel-Redirect”头或者error_page有内部跳转，那么这些服务器组之间会以冒号隔开，比如：“192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock : 192.168.10.1:80, 192.168.10.2:80”。$upstream_response_time以毫秒的精度保留服务器的响应时间，（输出）单位是秒。 出现多个响应时，也是以逗号和冒号隔开。$upstream_status保存服务器的响应代码。 出现多个响应时，也是以逗号和冒号隔开。$upstream_http_...保存服务器的响应头的值。比如“Server”响应头的值可以通过$upstream_http_server变量来获取。 需要注意的是只有最后一个响应的头会被保留下来。 nginx rewrite 指令nginx通过ngx_http_rewrite_module模块支持url重写、支持if条件判断，但不支持else。 该模块需要PCRE支持，应在编译nginx时指定PCRE源码目录, nginx安装方法。 nginx rewrite指令执行顺序：1.执行server块的rewrite指令(这里的块指的是server关键字后{}包围的区域，其它xx块类似)2.执行location匹配3.执行选定的location中的rewrite指令如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件 如果循环超过10次，则返回500 Internal Server Error错误 break指令语法：break;默认值：无作用域：server,location,if 停止执行当前虚拟主机的后续rewrite指令集break指令实例： 1234 if ($slow) { limit_rate 10k; break; } if指令语法：if(condition){…}默认值：无作用域：server,location对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行。if条件(conditon)可以是如下任何内容: 一个变量名；false如果这个变量是空字符串或者以0开始的字符串； 使用= ,!= 比较的一个变量和字符串 是用~， ~*与正则表达式匹配的变量，如果这个正则表达式中包含}，;则整个表达式需要用” 或’ 包围 使用-f ，!-f 检查一个文件是否存在 使用-d, !-d 检查一个目录是否存在 使用-e ，!-e 检查一个文件、目录、符号链接是否存在 使用-x ， !-x 检查一个文件是否可执行 if指令实例 12345678910111213141516171819 if ($http_user_agent ~ MSIE) { rewrite ^(.)$ /msie/$1 break; } if ($http_cookie ~ “id=([^;]+)(?:;|$)”) { set $id $1; } if ($request_method = POST) { return 405; } if ($slow) { limit_rate 10k; } if ($invalid_referer) { return 403; } return指令语法：return code; return code URL; return URL;默认值：无作用域：server,location,if 停止处理并返回指定状态码(code)给客户端。非标准状态码444表示关闭连接且不给客户端发响应头。从0.8.42版本起，return 支持响应URL重定向(对于301，302，303，307），或者文本响应(对于其他状态码).对于文本或者URL重定向可以包含变量 rewrite指令语法：rewrite regex replacement [flag];默认值：无作用域：server,location,if如果一个URI匹配指定的正则表达式regex，URI就按照replacement重写。rewrite按配置文件中出现的顺序执行。flags标志可以停止继续处理。如果replacement以”http://“或”https://“开始，将不再继续处理，这个重定向将返回给客户端。flag可以是如下参数last 停止处理后续rewrite指令集，然后对当前重写的新URI在rewrite指令集上重新查找。break 停止处理后续rewrite指令集，并不在重新查找,但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行。redirect 如果replacement不是以http:// 或https://开始，返回302临时重定向permant 返回301永久重定向最终完整的重定向URL包括请求scheme(http://,https://等),请求的server_name_in_redirect和 port_in_redirec三部分 ，说白了也就是http协议 域名 端口三部分组成。 rewrite实例 1234567 server { … rewrite ^(/download/.)/media/(.)..$ $1/mp3/$2.mp3 last; rewrite ^(/download/.)/audio/(.)..$ $1/mp3/$2.ra last; return 403; … } 如果这些rewrite放到 “/download/” location如下所示, 那么应使用break而不是last , 使用last将循环10次匹配，然后返回 500错误: 12345 location /download/ { rewrite ^(/download/.)/media/(.)..$ $1/mp3/$2.mp3 break; rewrite ^(/download/.)/audio/(.)..$ $1/mp3/$2.ra break; return 403; } 对于重写后的URL（replacement）包含原请求的请求参数，原URL的?后的内容。如果不想带原请求的参数 ，可以在replacement后加一个问号。如下，我们加了一个自定义的参数user=$1,然后在结尾处放了一个问号?,把原请的参数去掉。 1 rewrite ^/users/(.*)$ /show?user=$1? last; 如果正则表达regex式中包含 “&#125;” 或 “;”, 那么整个表达式需要用双引号或单引号包围. rewrite_log指令语法：rewrite_log on|off;默认值：rewrite_log off;作用域：http,server,location,if开启或关闭以notice级别打印rewrite处理日志到error log文件。 nginx打开rewrite log例子 rewrite_log on;error_log logs/xxx.error.log notice; 1.打开rewrite on2.把error log的级别调整到 notice set指令语法：set variable value;默认值：none作用域：server,location,if定义一个变量并赋值，值可以是文本，变量或者文本变量混合体。 uninitialized_variable_warn指令语法：uninitialized_variable_warn on | off;默认值：uninitialized_variable_warn on作用域：http,server,location,if 控制是否输出为初始化的变量到日志 nginx的虚拟主机功能（nginx多站点，绑定多个域名）两个虚拟主机(纯静态-html 支持) - Two Virtual Hosts, Serving Static Files1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980http &#123; server &#123; listen 80; server_name www.domain1.com; access_log logs/domain1.access.log main; location / &#123; index index.html; root /var/www/domain1.com/htdocs; &#125; &#125; server &#123; listen 80; server_name www.domain2.com; access_log logs/domain2.access.log main; location / &#123; index index.html; root /var/www/domain2.com/htdocs; &#125; &#125;&#125; 虚拟主机标准配置(简化) - A Default Catchall Virtual Hosthttp &#123; server &#123; listen 80 default; server_name _ *; access_log logs/default.access.log main; location / &#123; index index.html; root /var/www/default/htdocs; &#125; &#125;&#125; 在父文件夹中建立子文件夹以指向子域名 - Wildcard Subdomains in a Parent Folder这是一个添加子域名(或是当DNS已指向服务器时添加一个新域名)的简单方法。需要注意的是，我已经将FCGI配置进该文件了。如果你只想使服务器为静态文件服务，可以直接将FCGI配置信息注释掉，然后将默认主页文件变成index.html。这个简单的方法比起为每一个域名建立一个 vhost.conf 配置文件来讲，只需要在现有的配置文件中增加如下内容：This is just a really easy way to keep adding new subdomains, or to add new domains automatically when DNS records are pointed at the server. Note that I have included FCGI here as well. If you want to just serve static files, strip out the FCGI config and change the default document to index.html. Rather than creating a new vhost.conf file for every domain, just create one of these:server &#123; # Replace this port with the right one for your requirements # 根据你的需求改变此端口 listen 80; #could also be 1.2.3.4:80 也可以是1.2.3.4:80的形式 # Multiple hostnames seperated by spaces. Replace these as well. # 多个主机名可以用空格隔开，当然这个信息也是需要按照你的需求而改变的。 server_name star.yourdomain.com *.yourdomain.com www.*.yourdomain.com; #Alternately: _ * #或者可以使用：_ * (具体内容参见本维基其他页面) root /PATH/TO/WEBROOT/$host; error_page 404 http://yourdomain.com/errors/404.html; access_log logs/star.yourdomain.com.access.log; location / &#123; root /PATH/TO/WEBROOT/$host/; index index.php; &#125; # serve static files directly # 直接支持静态文件 (爱月说：???从配置上看来不是直接支持啊～有问题有问题～) location ~* ^.+.(jpg|jpeg|gif|css|png|js|ico|html)$ &#123; access_log off; expires 30d; &#125; location ~ .php$ &#123; # By all means use a different server for the fcgi processes if you need to # 如果需要，你可以为不同的FCGI进程设置不同的服务信息 fastcgi_pass 127.0.0.1:YOURFCGIPORTHERE; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /PATH/TO/WEBROOT/$host/$fastcgi_script_name; fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_intercept_errors on; &#125; location ~ /.ht &#123; deny all; &#125; &#125; 如何使用nginx配置负载均衡123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161负载均衡是扩展应用程序并提高其性能和冗余的绝佳方法。Nginx是一种流行的Web服务器软件，可以配置为简单但功能强大的负载均衡器，以提高服务器资源的可用性和效率。在负载 均衡配置中，nginx充当在多个单独服务器上工作的分布式Web应用程序的单个入口点。在Web场上进行负载平衡本文介绍如何使用nginx为云服务器配置负载均衡。作为先决条件，您需要至少安装两台主机并安装Web服务器软件，以便了解负载均衡器的优势。安装nginx目前，最新版本的CentOS，Debian和Ubuntu都提供nginx软件包，可以使用命令快速安装nginx。#Debian和Ubuntu sudo apt-get update #然后安装Nginx开源版 sudo apt-get install nginx#Debian和Ubuntu sudo apt-get update #然后安装Nginx开源版 sudo apt-get install nginx#CentOS #安装额外的软件包存储库 sudo yum install epel-release#更新存储库并安装Nginx sudo yum update sudo yum install nginx#CentOS #安装额外的软件包存储库 sudo yum install epel-release#更新存储库并安装Nginx sudo yum update sudo yum install nginx安装完成后，进入nginx主配置文件夹。cd /etc/nginx/根据您的操作系统不同，Web服务器配置文件将位于两个位置之一。Ubuntu和Debian遵循在 /etc/nginx/sites-available/中存储虚拟主机文件的规则，这些规则通过符号链接到 /etc/nginx/sites-enabled/来启用。可以使用以下命令启用任何新的虚拟主机文件。sudo ln -s /etc/nginx/sites-available/vhost /etc/nginx/sites-enabled/vhostCentOS用户可以在/etc/nginx/conf.d/下找到其主机配置文件，nginx会加载此文件加下所有.conf类型的虚拟主机文件。可以在这个目录中至少找到一个默认配置default.conf，然后重新启动nginx。sudo systemctl restart nginx通过在Web浏览器中打开负载均衡服务器的IP地址来测试服务器是否回复HTTP请求。当您看到nginx的默认欢迎页面时，nginx安装成功。Nginx默认欢迎页面。如果您在加载页面时遇到问题，请检查防火墙是否阻止了您的连接。例如，在CentOS 7上，默认防火墙规则不允许HTTP流量，请使用以下命令启用它。sudo firewall-cmd --add-service=http --permanent sudo firewall-cmd --reload然后尝试刷新浏览器。将nginx配置为负载均衡器安装并测试nginx后，您可以开始配置nginx以实现负载平衡功能。从本质上讲，需要做的就是设置nginx，其中包含要监听的连接类型以及重定向位置的说明。要实现此目的，请使用您喜欢的任何文本编辑器创建新的配置文件，例如使用vi：sudo vi /etc/nginx/conf.d/load-balancer.conf在load-balancer.conf中，您需要定义以下两个段：upstream 和server ，请参阅下面的示例。#定义要包含在负载均衡方案中的服务器。 #最好使用服务器的私有IP以获得更好的性能和安全性。 http &#123; upstream backend &#123; server 10.1.0.101; server 10.1.0.102; server 10.1.0.103; &#125; #该服务器接受到端口80的所有流量并将其传递给上游upstream 。 #请注意，upstream名称和proxy_pass需要匹配。 server &#123; listen 80; location / &#123; proxy_pass http://backend; &#125; &#125; &#125;然后保存文件并退出编辑器。接下来，您需要禁用先前在安装后测试的默认服务器配置。同样取决于您的操作系统，这部分略有不同。在Debian和Ubuntu系统上，您需要从启用站点的文件夹中删除默认符号链接。sudo rm /etc/nginx/sites-enabled/defaultCentOS的主机不使用相同的链接，而是简单地将重命名default.conf在conf.d /目录下的东西，不是结束的.conf，例如：sudo mv /etc/nginx/conf.d/default.conf /etc/nginx/conf.d/default.conf.disabled然后使用以下命令重新启动nginxsudo systemctl restart nginx检查nginx是否成功启动。如果重新启动失败，请查看刚刚创建的 /etc/nginx/conf.d/load-balancer.conf，以确保没有错误类型或缺少分号。在Web浏览器中输入负载均衡nginx的IP地址时，请求会被传递到后端其中一个服务器。负载均衡方法如果没有定义其他方法，默认情况下nginx负载均衡会使用循环算法，如上面的第一个示例所示。使用循环方案，将根据您在load-balancer.conf 文件中设置的顺序轮流选择每个服务器。这平衡了短期操作的请求数量。基于最少连接的负载均衡是另一种简单的方法。顾名思义，此方法将请求定向到当时具有最少活动连接的服务器。对于请求有时可能需要更长时间才能完成的应用程序，它比循环法更有效。要启用最少连接均衡方法，请将参数least_conn添加到上游 部分，如下例所示。upstream backend &#123; least_conn; server 10.1.0.101; server 10.1.0.102; server 10.1.0.103; &#125;虽然循环和最少连接平衡方案是公平的并且有其用途，但是它们不能提供会话持久性。如果您的Web应用程序要求用户随后被定向到与之前连接相同的后端服务器，则应使用IPhash方法。IPhash使用访问者IP地址作为密钥来确定应选择哪个主机来为请求提供服务。这允许访问者每次被定向到同一服务器。要使用此方法，请将ip_hash 添加到 upstream 段，如下面的示例所示。upstream backend &#123; ip_hash; server 10.1.0.101; server 10.1.0.102; server 10.1.0.103; &#125;在一组主机之间的可用资源不相等的服务器配置中，可能希望某些服务器优先于其它服务器。定义服务器权重允许您进一步微调 nginx 负载均衡。负载均衡中权重最高的服务器最常选择。upstream backend &#123; server 10.1.0.101 weight=4; server 10.1.0.102 weight=2; server 10.1.0.103; &#125;例如，在上面的配置中，第一个服务器的选择频率是第二个服务器的两倍，是第三个服务器的四倍。启用HTTPS的负载均衡为您的网站启用HTTPS是保护访问者及其数据的好方法。建议大家开启https，可以提高搜索排名。了解如何在nginx上安装Let&#x27;s Encrypt。在负载均衡器中使用https加密比想象的要容易。需要做的就是在负载均衡器配置文件中添加另一个服务器server，该server使用SSL监听端口443上的HTTPS流量，并为 upstream 段设置 proxy_pass ，就像上一个示例中的HTTP一样。再次打开配置文件进行编辑。sudo vi /etc/nginx/conf.d/load-balancer.conf然后将以下服务器段添加到文件末尾。server &#123; listen 443 ssl; server_name domain_name; ssl_certificate /etc/letsencrypt/live/domain_name/cert.pem; ssl_certificate_key /etc/letsencrypt/live/domain_name/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; location / &#123; proxy_pass http://backend; &#125; &#125;然后保存文件，退出编辑器并再次重新启动nginx。sudo systemctl restart nginx健康检查为了知道哪些服务器可用，nginx的反向代理实现包括被动服务器健康检查。如果服务器无法响应请求或回复错误，nginx会检测到服务失败，并将尝试一段时间内避免转发请求到该服务器。通过将参数max_fails设置为服务器行，可以在负载均衡器配置文件中定义特定时间段内连续不成功的连接尝试次数。默认情况下，如果未指定max_fails，则将此值设置为1.（可选）将max_fails设置为0将禁用对该服务器的运行状况检查。如果将max_fails设置为大于1的值，则后续失败必须在特定时间范围内发生，以便无法计数。此时间范围由参数fail_timeout指定，该参数还定义服务器应被视为失败的时间。默认情况下，fail_timeout设置为10秒。在服务器标记失败并且fail_timeout设置的时间已过后，nginx将开始使用客户端请求正常探测服务器。如果探测返回成功，则服务器再次标记为可用并且正常包含在负载平衡中。upstream backend &#123; server 10.1.0.101 weight=5; server 10.1.0.102 max_fails=3 fail_timeout=30s; server 10.1.0.103; &#125;使用运行状况检查可以根据需要通过启动或关闭主机来使服务器后端适应当前需求。在高流量期间启动其他服务器可以在新资源自动供负载均衡器使用时轻松提高应用程序性能。结论如果您希望提高Web应用程序的性能和可用性，那么设置负载均衡器绝对值得考虑。使用nginx进行负载均衡功能强大且设置相对简单，并且与简单的加密解决方案（例如Let&#x27;s Encrypt客户端）一起使用，它为您的Web场提供了一个很好的前端。虽然使用多个主机可以保护您的Web服务具有冗余，但负载均衡器本身仍然可能单点故障。您可以通过在多个nginx之间设置浮动IP来进一步提高高可用性。 使用nginx的proxy_cache做网站缓存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152为什么要做web cache，我想大家最主要的是解决流量的压力。随着网站流量的提升，如果只是单台机器既处理静态文件，又处理动态脚本，显然效率很难上升，不能处理日益上涨的流量压力。与此同时某些网站的页面内容并不是经常变化，因此我们可以分两层架构来组织网站。前端web缓存+后端web服务器，可以参看这里配置nginx反向代理配置前端web缓存有多重方式实现，原理就是队请求结果页面静态化并设置一个超时期限，缓存页面过期后，新请求到达时重新到后端web服务器获取内容更新；没有nginx前比较流行的方法是squid，但squid不能充分利用处理器的多核特性，越来越多的网站选用nginx来做前端的web缓存。要想使用nginx的缓存功能要保证nginx添加了proxy模块。我们可以使用-V选项(大写的V，小写的v是看版本号的)来查看nginx的编译参数。我使用的是默认的参数编译的，如下所示：root@SNDA-172-17-12-117:/usr/local/nginx# ./nginx -Vnginx version: nginx/1.2.3built by gcc 4.4.3 (Ubuntu 4.4.3-4ubuntu5.1)TLS SNI support enabledconfigure arguments: --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.21 --with-zlib=/usr/local/src/zlib-1.2.7nginx的所有模块必须在编译的时候添加，不能再运行的时候动态加载，默认的编译选项下包含的模块，如果你不是显示的用参数关闭它。nginx默认安装的模块如下模块名称 描述 版本 如何禁用Core Control ports, locations, error pages, aliases, and other essentials. --without-httpAccess Allow/deny based on IP address. --without-http_access_moduleAuth Basic Basic HTTP authentication. --without-http_auth_basic_moduleAuto Index Generates automatic directory listings. --without-http_autoindex_moduleBrowser Interpret &quot;User-Agent&quot; string. 0.4.3 --without-http_browser_moduleCharset Recode web pages. --without-http_charset_moduleEmpty GIF Serve a 1x1 image from memory. 0.3.10 --without-http_empty_gif_moduleFastCGI FastCGI Support. --without-http_fastcgi_moduleGeo Set config variables using key/value pairs of IP addresses. 0.1.17 --without-http_geo_moduleGzip Gzip responses. --without-http_gzip_moduleHeaders Set arbitrary HTTP response headers. Index Controls which files are to be used as index. Limit Requests Limit frequency of connections from a client. 0.7.20 --without-http_limit_req_moduleLimit Zone Limit simultaneous connections from a client. Deprecated in 1.1.8, use Limit Conn Instead. 0.5.6 --without-http_limit_zone_moduleLimit Conn Limit concurrent connections based on a variable. --without-http_limit_conn_moduleLog Customize access logs. Map Set config variables using arbitrary key/value pairs. 0.3.16 --without-http_map_moduleMemcached Memcached support. --without-http_memcached_moduleProxy Proxy to upstream servers. --without-http_proxy_moduleReferer Filter requests based on Referer header. --without-http_referer_moduleRewrite Request rewriting using regular expressions. --without-http_rewrite_moduleSCGI SCGI protocol support. 0.8.42 --without-http_scgi_moduleSplit Clients Splits clients based on some conditions 0.8.37 --without-http_split_clients_moduleSSI Server-side includes. --without-http_ssi_moduleUpstream For load-balancing. --without-http_upstream_ip_hash_module (ip_hash directive only)User ID Issue identifying cookies. --without-http_userid_moduleuWSGI uWSGI protocol support. 0.8.40 --without-http_uwsgi_moduleX-Accel X-Sendfile-like module. proxy模块中常用的指令时proxy_pass和proxy_cache.nginx的web缓存功能的主要是由proxy_cache、fastcgi_cache指令集和相关指令集完成，proxy_cache指令负责反向代理缓存后端服务器的静态内容，fastcgi_cache主要用来处理FastCGI动态进程缓存(这里我不是很清楚这两个指令的区别，好像功能上都差不多，尤其后面这句话的意思，是我翻译过来的)。确认proxy模块安装好后，下面对nginx的配置文件进行设置，重点部分如标红字体所示。这是我的nginx.conf配置文件。user www-data;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123;worker_connections 1024;&#125;http &#123;include mime.types;default_type application/octet-stream;log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$host&quot;&#x27;;#access_log logs/access.log main;sendfile on;#tcp_nopush on;#keepalive_timeout 0;keepalive_timeout 65;#Compression Settingsgzip on;gzip_http_version 1.0;gzip_comp_level 2;gzip_proxied any;gzip_min_length 1100;gzip_buffers 16 8k;gzip_types text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript;# Some version of IE 6 don&#x27;t handle compression well on some mime-types,# so just disable for themgzip_disable &quot;MSIE [1-6].(?!.*SV1)&quot;;# Set a vary header so downstream proxies don&#x27;t send cached gzipped# content to IE6gzip_vary on;#end gzip#cache beginproxy_buffering on;proxy_cache_valid any 10m;proxy_cache_path /data/cache levels=1:2 keys_zone=my-cache:8m max_size=1000m inactive=600m;proxy_temp_path /data/temp;proxy_buffer_size 4k;proxy_buffers 100 8k;#cache end## Basic reverse proxy server #### Apache (vm02) backend for www.example.com ##upstream apachephp &#123;server www.quancha.cn:8080; #Apache1&#125;## Start www.quancha.cn ##server &#123;listen 80;server_name *.quancha.cn;access_log logs/quancha.access.log main;error_log logs/quancha.error.log;root html;index index.html index.htm index.php;## send request back to apache1 ##location / &#123;proxy_pass http://apachephp;proxy_cache my-cache;proxy_cache_valid 200;#Proxy Settingsproxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;proxy_max_temp_file_size 0;proxy_connect_timeout 90;proxy_send_timeout 90;proxy_read_timeout 90;proxy_buffer_size 4k;proxy_buffers 4 32k;proxy_busy_buffers_size 64k;proxy_temp_file_write_size 64k;##End Proxy Settings&#125;&#125;## End www.quancha.cn ##&#125;配置文件中以proxy_开头的指令我们大都可以字面意思得到理解。请务必注意一点proxy_cache_path和proxy_temp_path设置的目录需要在同一分区，因为它们之间是硬链接的关系。最后启动nginx，来迎接着激动人心的时刻吧。我已经迫不及待了。如果文章哪里有问题或者你遇到了什么麻烦，可以留言让我知道。 nginx屏蔽ip12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455采集和防止采集是一个经久不息的话题，一方面都想搞别人的东西，另一方面不想自己的东西被别人搞走。本文介绍如何利用nginx屏蔽ip来实现防止采集，当然也可以通过iptable来实现。1.查找要屏蔽的ipawk &#x27;&#123;print $1&#125;&#x27; nginx.access.log |sort |uniq -c|sort -nnginx.access.log 为日志文件，会到如下结果，前面是ip的访问次数，后面是ip，很明显我们需要把访问次数多的ip并且不是蜘蛛的ip屏蔽掉，本例当中我们屏蔽掉165.91.122.67 ... 13610 202.112.113.192 95772 180.169.22.135 337418 219.220.141.2 558378 165.91.122.672.在nginx的安装目录下面,新建屏蔽ip文件，命名为blockip.conf，以后新增加屏蔽ip只需编辑这个文件即可。 加入如下内容deny 165.91.122.67; 保存一下。3.在nginx的配置文件nginx.conf中加入如下配置，可以放到http, server, location, limit_except语句块，需要注意相对路径，本例当中nginx.conf，blocksip.conf在同一个目录中。include blockip.conf; 4.重启一下nginx的服务：/usr/local/nginx/nginx -s reload 就可以生效了。高级用法：屏蔽ip的配置文件既可以屏蔽单个ip，也可以屏蔽ip段，或者只允许某个ip或者某个ip段访问。# 屏蔽单个ip访问deny IP; # 允许单个ip访问allow IP; # 屏蔽所有ip访问deny all; # 允许所有ip访问allow all; #屏蔽整个段即从123.0.0.1到123.255.255.254访问的命令deny 123.0.0.0/8#屏蔽IP段即从123.45.0.1到123.45.255.254访问的命令deny 124.45.0.0/16#屏蔽IP段即从123.45.6.1到123.45.6.254访问的命令deny 123.45.6.0/24如果你想实现这样的应用，除了几个IP外，其他全部拒绝，那需要你在blockip.conf中这样写allow 1.1.1.1; allow 1.1.1.2;deny all; 单独网站屏蔽IP的方法，把include blocksip.conf; 放到网址对应的在server&#123;&#125;语句块，所有网站屏蔽IP的方法，把include blocksip.conf; 放到http &#123;&#125;语句块。 nginx “403 Forbidden” 错误12345678910111213141516171819202122232425262728293031323334353637383940nginx 的 403 Forbidden errors 表示你在请求一个资源文件但是nginx不允许你查看。403 Forbidden 只是一个HTTP状态码，像404,200一样不是技术上的错误。哪些场景需要返回403状态码的场景？1.网站禁止特定的用户访问所有内容，例：网站屏蔽某个ip访问。2.访问禁止目录浏览的目录，例：设置autoindex off后访问目录。3.用户访问只能被内网访问的文件。以上几种常见的需要返回 403 Forbidden 的场景。由于服务器端的错误配置导致在不希望nginx返回403时返回403 Forbidden。1.权限配置不正确这个是nginx出现403 forbidden最常见的原因。为了保证文件能正确执行，nginx既需要文件的读权限,又需要文件所有父目录的可执行权限。例如，当访问/usr/local/nginx/html/image.jpg时，nginx既需要image.jpg文件的可读权限，也需要/,/usr,/usr/local,/usr/local/nginx,/usr/local/nginx/html的可以执行权限。解决办法:设置所有父目录为755权限，设置文件为644权限可以避免权限不正确。 2.目录索引设置错误（index指令配置）网站根目录不包含index指令设置的文件。例如，运行PHP的网站，通常像这样配置indexindex index.html index.htm index.php;当访问该网站的时，nginx 会按照 index.html，index.htm ，index.php 的先后顺序在根目录中查找文件。如果这三个文件都不存在，那么nginx就会返回403 Forbidden。如果index中不定义 index.php ，nginx直接返回403 Forbidden而不会去检查index.php是否存在。同样对于如果运行jsp, py时也需要添加index.jsp,index.py到目录索引指令index中。解决办法:添加首页文件到index指令，常见的是index.php，index.jsp，index.jsp或者自定义首页文件。 nginx File not found 错误123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475使用php-fpm解析PHP，&quot;No input file specified&quot;，&quot;File not found&quot;是令nginx新手头疼的常见错误，原因是php-fpm进程找不到SCRIPT_FILENAME配置的要执行的.php文件，php-fpm返回给nginx的默认404错误提示。比如我的网站doucument_root下没有test.php，访问这个文件时通过抓包可以看到返回的内容。HTTP/1.1 404 Not FoundDate: Fri, 21 Dec 2012 08:15:28 GMTContent-Type: text/htmlProxy-Connection: closeServer: nginx/1.2.5X-Powered-By: PHP/5.4.7Via: 1.1 c3300 (NetCache NetApp/6.0.7)Content-Length: 16File not found. 很多人不想用户直接看到这个默认的404错误信息，想自定义404错误.给出解决办法前我们来先分析下如何避免出现这类404错误，然后再说真的遇到这种情况(比如用户输入一个错误不存在的路径)时该怎么办，才能显示自定义的404错误页。一、错误的路径被发送到php-fpm进程出现这类错误，十个有九个是后端fastcgi进程收到错误路径(SCRIPT_FILENAME)，而后端fastcgi收到错误路径的原因大都是配置错误。常见的nginx.conf的配置如下：server &#123; listen [::]:80; server_name example.com www.example.com; access_log /var/www/logs/example.com.access.log; location / &#123; root /var/www/example.com; index index.html index.htm index.pl; &#125; location /images &#123; autoindex on; &#125; location ~ .php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /var/www/example.com$fastcgi_script_name; include fastcgi_params; &#125;&#125;这个配置中有很多不合理的地方，其中一个明显的问题就是root指令被放到了location / 块。如果root指令被定义在location块中那么该root指令只能对其所在的location生效。其它locaiont中没有root指令，像location /images块不会匹配任何请求，需要在每个请求中重复配置root指令来解决这个问题。因此我们需要把root指令放在server块，这样各个location就会继承父server块定义的$document_root，如果某个location需要定义一个不同的$document_root，则可以在location单独定义一个root指令。另一个问题就是fastCGI参数SCRIPT_FILENAME 是写死的。如果修改了root指令的值或者移动文件到别的目录，php-fpm会返回“No input file specified”错误，因为SCRIPT_FILENAME在配置中是写死的并没有随着$doucument_root变化而变化，我们可以修改SCRIPT_FILENAME配置如下：fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; 所以我们不能忘记在server块中配置root指令，不然$document_root的值为空，只会传$fastcgi_script_name到php-fpm，这样就会导致“No input file specified”错误。 二、请求的文件真的不存在当nginx收到一个不在的.php文件的请求时,因为nginx只会检查$uri是否是.php结尾，不会对文件是否存在进行判断，.php结尾的请求nginx会直接发给php-fpm处理。php-fpm处理时找不到文件就会返回“No input file specified”带着“404 Not Found”头。解决办法我们在nginx拦截不存在的文件，请求并返回自定义404错误使用 try_files 捕捉不存在的urls并返回错误。location ~ .php$ &#123; try_files $uri =404; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME .... ................................... ...................................&#125;上面的配置会检查.php文件是否存在，如果不存在，会返回404页面。 nginx将POST数据写到日志里123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158NGINX 是一个强大的web服务器，可以很容易的应对高负载的HTTP流量。nginx每处理一个连接，就会记录一条日志信息，包括诸如：IP地址，回复内容大小、http状态码等信息。某种情况下，需要了解请求内容是什么，特别 POST 请求。 NGINX 默认只支持记录GET请求，对于记录POST请求需要使用额外的模块，例如， Echo module, 这个模块提供很多有用的指令: echo, time, and sleep。记录POST请求我们需要使用到其中的 echo_read_request_body 命令和 $request_body 变量。源码编译nginx增加echo模块步骤:1.下载nginx和echo模块的源码：curl -L -O &#x27;https://github.com/openresty/echo-nginx-module/archive/v0.61.tar.gz&#x27;tar -xzvf v0.61.tar.gz &amp;&amp; rm -f v0.61.tar.gzmv echo-nginx-module-0.61 /tmp/echo-nginx-modulewget https://www.openssl.org/source/openssl-1.1.1g.tar.gztar -zxvf openssl-1.1.1g.tar.gz &amp;&amp; openssl-1.1.1g.tar.gzmv openssl-1.1.1g /tmp/openssl-1.1.1gcurl -O &#x27;http://nginx.org/download/nginx-1.18.0.tar.gz&#x27;tar -xzvf nginx-1.18.0.tar.gz &amp;&amp; rm -f nginx-1.18.0.tar.gz2.创建 nginx 用户， 用来运行nginx进程：groupadd nginxuseradd -g nginx nginx3.从源码编译安装nginx：cd nginx-1.18.0/ &amp;&amp; ./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-pcre \\ --with-file-aio \\ --with-http_realip_module \\ --with-openssl=/tmp/openssl-1.1.1g \\ --add-module=/tmp/echo-nginx-module make -j2make install 现在，nginx已安装完成，可以启动了。启动之前我们需要修改nginx的默认配置文件 /usr/local/nginx/conf/nginx.conf 来记录 HTTP request body 到日志文件。NGINX 使用 access_log 指令记录多种 HTTP 请求相关的信息，哪些信息会或不会被记录则通过 log_format 指令来设置。Echo 模块通过调用 echo_read_request_body 方法存储 request body 到 request_body 变量中。为了记录 POST 请求体需要在配置文件中修改这些指令:http &#123; ... log_format custom &#x27;$request_body&#x27;; access_log logs/access.log custom; ... server &#123; location / &#123; echo_read_request_body; ... &#125; &#125;&#125;如果你的系统负载很高，你可以通过提高Linux打开文件数参数的大小来提高 NGINX 的处理能力。通过如下指令增加配置到文件末尾或直接修改相应的配置文件。echo &quot;fs.file-max = 1073741824&quot; &gt;&gt; /etc/sysctl.confecho &quot;nginx soft nofile 40960&quot; &gt;&gt; /etc/security/limits.confecho &quot;nginx hard nofile 81920&quot; &gt;&gt; /etc/security/limits.conf终于可以启动nginx并记录POST的请求内容了，运行nginx命令：/usr/local/nginx/sbin/nginx测试修改配置文件增加上面提到的三个配置。[root@67 nginx]# cd /usr/local/nginx/conf/[root@67 conf]# vi nginx.conf测试并重新加载配置文件[root@67 conf]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@67 conf]# /usr/local/nginx/sbin/nginx -s reload不带post参数会记录一个短横[root@67 conf]# curl 127.0.0.1[root@67 conf]# curl 127.0.0.1[root@67 conf]# cd ../logs/[root@67 logs]# tail -f access.log --[root@67 logs]# curl -d &quot;site=redis.com.cn&quot; 127.0.0.1[root@67 logs]# tail -f access.log --site=redis.com.cn排错1.checking for getaddrinfo() ... foundconfiguring additional modulesadding module in /tmp/echo-nginx-module/tmp/echo-nginx-module/config: line 41: [: !=: unary operator expected + ngx_http_echo_module was configuredchecking for PCRE library ... not foundchecking for PCRE library in /usr/local/ ... not foundchecking for PCRE library in /usr/include/pcre/ ... not foundchecking for PCRE library in /usr/pkg/ ... not foundchecking for PCRE library in /opt/local/ ... not found./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option.缺少PCRE、ZLIB参考nginx安装教程先安装对应的源码包2.checking for OpenSSL library ... not foundchecking for OpenSSL library in /usr/local/ ... not foundchecking for OpenSSL library in /usr/pkg/ ... not foundchecking for OpenSSL library in /opt/local/ ... not found需要下载opensll包，参考nginx安装cd /tmpwget https://www.openssl.org/source/openssl-1.1.1g.tar.gztar -zxvf openssl-1.1.1g.tar.gz--with-openssl=/tmp/openssl-1.1.1g总结，本文主要介绍了如果配置nginx的日志记录功能，以及如何编译、安装、和使用echo模块。参考：developers.redhat.com/blog/2016/05/23/configuring-nginx-to-log-post-data-on-linux-rhel/","categories":[{"name":"服务","slug":"服务","permalink":"http://example.com/categories/%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://example.com/tags/nginx/"}]},{"title":"开发工具软件及IDE","slug":"开发工具软件及IDE","date":"2020-09-18T08:44:20.000Z","updated":"2020-09-18T08:45:12.717Z","comments":true,"path":"2020/09/18/开发工具软件及IDE/","link":"","permalink":"http://example.com/2020/09/18/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E8%BD%AF%E4%BB%B6%E5%8F%8AIDE/","excerpt":"","text":"开发工具软件及IDE​ 一款很好用的轻量级IDE VSCODE VSCODE 是由微软开发的一款IDE工具，拥有非常丰富的插件可以在线下载安装，并且启动的速度灰常快，biu~ 我一般来进行 JS、Python、Go等语言的开发。 在线代码仓库 腾讯的coding 在线的且免费使用的代码仓库，目前没有人数限制 MarkDown 编写工具 Typora 神器，目前用的最顺手的，无需解释。 跨平台的密码管理工具 BitWarDen 相比于 1Password 而言，这款工具完全免费，且功能和1password基本一模一样，该有的都有，包括win/mac、ios/Android、各种浏览器插件，使用非常方便。 移动端、小程序、公众号开发框架 Taro 目前Taro的开发支持React 及 Vue语法，并且有配套的TaroUI配合使用，记住使用Taro3需要配合TaroUI3使用，否则会报错。 后台管理框架 AntDesign Pro 蚂蚁开源，可以使用各种Antd的组件，还可以尝试 一下 antd的升级版ui组件procomponents。 免费的博客搭建工具，连域名都不用去买 hexo + github.io 基于NodeJs的hexo 配合免费的github个人页面，使用markdown来编写博客页面，编写的文章可以一键更新到网页。 开源测试工具 MeterSphere 开源的好用的一款测试工具。 一款图床工具picGo 一款win/mac都可以使用图床工具，支持多种图床源","categories":[{"name":"tools","slug":"tools","permalink":"http://example.com/categories/tools/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"JavaScript文件对象详解","slug":"JavaScript文件对象详解","date":"2020-09-18T08:34:45.000Z","updated":"2020-09-18T08:36:29.711Z","comments":true,"path":"2020/09/18/JavaScript文件对象详解/","link":"","permalink":"http://example.com/2020/09/18/JavaScript%E6%96%87%E4%BB%B6%E5%AF%B9%E8%B1%A1%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"JavaScript 文件对象详解在浏览器中操作文件，多数情况下用到的是 File 对象，从 &lt;input type=&#39;file&#39; /&gt; 元素获取，进而继续操作(例如将选择的图片展示在页面上，用ajax将文件上传至服务器等)。这里介绍在浏览器中操作文件的相关API. File 对象继承自 Blob 对象，先看看 Blob 对象。 1. Blob 对象Blob 对象表示一个不可变、原始数据的类文件对象。Blob 表示的不一定是JavaScript原生格式的数据。 Blob构造函数 Blob(array[, options]) array 是一个由ArrayBuffer, ArrayBufferView, Blob, string 等对象构成的 Array ，或者其他类似对象的混合体，它将会被放进 Blob。string会被编码为UTF-8。 options 是一个可选的对象，它可能会指定如下两个属性： type，默认值为 “”，它代表了将会被放入到blob中的数组内容的MIME类型。 endings，默认值为”transparent”，用于指定包含行结束符\\n的字符串如何被写入。 它是以下两个值中的一个： “native”，代表行结束符会被更改为适合宿主操作系统文件系统的换行符，或者 “transparent”，代表会保持blob中保存的结束符不变。 示例: 12345var content1 = [&#x27;This is my firt trip to an island&#x27;];var blob1 = new Blob(content, &#123;type: &#x27;text/plain&#x27;&#125;);var content2 = &#123;name: &#x27;Alice&#x27;, age: 23&#125;;var blob2 = new Blob([JSON.stringify(content2, null, 2)], &#123;type: &#x27;application/json&#x27;&#125;);复制代码 Blob实例属性 属性名称 读/写 描述 size 只读 Blob 对象中所包含数据的大小（字节）。 type 只读 一个字符串，表明该Blob对象所包含数据的MIME类型。如果类型未知，则该值为空字符串。例如 “image/png”. 示例: 12345var content = [&#x27;&lt;div id=&quot;box&quot;&gt;&lt;p class=&quot;pra&quot;&gt;a paragraph&lt;/p&gt;&lt;/div&gt;&#x27;];var blob = new Blob(content, &#123;type: &#x27;text/html&#x27;&#125;);console.log(blob.size); // 50console.log(blob.type); // text/html复制代码 Blob实例方法 slice([start[, end[, contentType]]]) slice 方法接收三个可选参数，start 和 end 都是数值，表示截取的范围，contentType 指定截取的内容的 MIME 类型。返回一个新的 Blob对象。 12345var blob = new Blob([&#x27;This is an example of Blob slice method&#x27;], &#123;type: &#x27;text/plain&#x27;&#125;);console.log(blob.size); // 39var newBlob = blob.slice(10, 20, &#x27;text/plain&#x27;);console.log(newBlob.size); // 10复制代码 从 Blob 对象中读取内容可以使用 FileReader. 下文会介绍。 2. File 对象File构造函数我们接触的多数关于 File 的操作都是读取，js也为我们提供了手动创建 File 对象的构造函数：File(bits, name[, options])。 bits (required) ArrayBuffer，ArrayBufferView，Blob，或者 Array[string] — 或者任何这些对象的组合。这是 UTF-8 编码的文件内容。。 name [String] (required) 文件名称，或者文件路径. options [Object] (optional) 选项对象，包含文件的可选属性。可用的选项如下： type: string, 表示将要放到文件中的内容的MIME类型。默认值为 ‘’ 。 lastModified: 数值，表示文件最后修改时间的 Unix 时间戳（毫秒）。默认值为 Date.now()。 示例： 1var file1 = new File([&#x27;text1&#x27;, &#x27;text2&#x27;], &#x27;test.txt&#x27;, &#123;type: &#x27;text/plain&#x27;&#125;); 根据已有的 blob 对象创建 File 对象: 1var file2 = new File([blob], &#x27;test.png&#x27;, &#123;type: &#x27;image/png&#x27;&#125;); File实例属性File 对象的实例内容不可见，但是有以下属性可以访问: 属性名称 读/写 描述 name 只读 返回文件的名称.由于安全原因,返回的值并不包含文件路径 。 type 只读 返回 File 对象所表示文件的媒体类型（MIME）。例如 PNG 图像是 “image/png”. lastModified 只读 number, 返回所引用文件最后修改日期,自 1970年1月1日0:00 以来的毫秒数。 lastModifiedDate 只读 Date, 返回当前文件的最后修改日期,如果无法获取到文件的最后修改日期,则使用当前日期来替代。 示例： 12345678910&lt;input type=&quot;file&quot; id=&#x27;file&#x27;&gt;document.getElementById(&#x27;file&#x27;).addEventListener(&#x27;change&#x27;, function(event)&#123; const file = this.files[0]; if (file) &#123; console.log(file.name); console.log(file.size); console.log(file.lastModified); console.log(file.lastModifiedDate); &#125;&#125;); 备注: 基于当前的实现，浏览器不会实际读取文件的字节流，来判断它的媒体类型。它基于文件扩展来假设；将PNG 图像文件的后缀名重命名为 .txt，那么读取的该文件的 type 属性值为 “text/plain”， 而不是 “image/png” 。而且，file.type 仅仅对常见文件类型可靠。例如图像、文档、音频和视频。不常见的文件扩展名会返回空字符串。开发者最好不要依靠这个属性，作为唯一的验证方案。 File实例方法 slice([start[, end[, contentType]]]) File 对象没有定义额外的方法，由于继承了 Blob 对象，也就继承了 slice方法，用法同上文 Blob 的 slice 方法。 FileReader, URL.createObjectURL(), createImageBitmap(), 及 XMLHttpRequest.send() 都能处理 Blob 和 File。 3. FileReader 对象 FileReader 对象允许Web应用程序异步读取存储在用户计算机上的文件（或原始数据缓冲区）的内容，使用 File 或 Blob 对象指定要读取的文件或数据。 其中 File 对象可以是来自用户在一个 &lt;input&gt; 元素上选择文件后返回的 FileList, 也可以来自拖放操作生成的 DataTransfer 对象,还可以是来自在一个 HTMLCanvasElement 上执行 mozGetAsFile() 方法后返回结果。 FileReader构造函数1var reader = new FileReader() 构造函数不需要传入参数，返回一个 FileReader 的实例。FileReader 继承 EventTarget对象。 FileReader实例属性 属性名称 读/写 描述 error 只读 DOMException 的实例，表示在读取文件时发生的错误 。 result 只读 文件的内容，该属性仅在读取操作完成后(load)后才有效，格式取决于读取方法 readyState 只读 表示读取文件时状态的数字 备注: readeyState的取值如下: 值 常量名 描述 0 EMPTY 还没有加载任何数据 1 LOADING 数据正在被加载 2 DONE 已完成全部的读取请求. 使用示例： 1234567var reader = new FileReader();console.log(reader.error); // nullconsole.log(reader.result); // nullconsole.log(reader.readyState); // 0console.log(reader.EMPTY); // 0console.log(reader.LOADING); // 1console.log(reader.DONE); // 2 EMPTY、LOADING、DONE 这三个属性同时存在于 FileReader 和它的的原型对象上，因此实例上有这三个属性，FileReader 对象本身也有这三个属性: 123console.log(FileReader.EMPTY); // 0console.log(FileReader.LOADING); // 1console.log(FileReader.DONE); // 2 FileReader事件文件的读取是一个异步的过程，和 XMLHttpRequest 对象一样，在读取操作过程中会触发一系列事件。 事件名称 描述 使用示例 abort 读取操作被中断时触发。 reader.onabort = function(event) &#123;&#125; error 在读取操作发生错误时触发。 reader.onerror = function(event) &#123;&#125; load 读取操作完成时触发。 reader.addEventListener(&#39;load&#39;, function(event) &#123;&#125;) loadstart 读取操作开始时触发。 reader.onloadstart = function(event) &#123;&#125; loadend 读取操作结束时（要么成功，要么失败）触发。 reader.onloadend = function(event) &#123;&#125; progress 在读取Blob时触发。 reader.onprogress = function(event) &#123;&#125; FileReader实例方法FileReader 的实例具有以下可操作的方法: 方法名称 描述 使用示例 abort() 手动终止读取操作，只有当 readyState 为 1 时才能调用，调用后，readyState 值为 2 reader.abort() readAsArrayBuffer(blob) 读取指定的 Blob 或 File 对象。读取操作完成后(触发loadend事件)，result属性将包含一个 ArrayBuffer 对象表示所读取的文件的数据。 reader.readAsArrayBuffer(blob) readAsDataURL(blob) 读取指定的 Blob 或 File 对象。读取操作完成后(触发loadend事件)，result属性将包含一个 data:URL 格式的字符串(base64编码) reader.readAsArrayBuffer(file) readAsBinaryString(blob) 已废弃，用 readAsArrayBuffer 代替 – readAsText(blob[, encoding]) 将 Blob 或者 File 对象转根据特殊的编码格式转化为内容(字符串形式), 默认编码是 utf-8 reader.readAsArrayBuffer(blob) 读取本地图片示例: 12345678910111213&lt;input type=&quot;file&quot; id=&#x27;file&#x27; accept=&quot;image/png, image/jpg, image/jpeg, image/gif&quot; /&gt;&gt;&lt;br /&gt;&gt;&lt;img src=&quot;&quot; alt=&quot;Image preview...&quot;&gt;var preview = document.querySelector(&#x27;img&#x27;);var reader = new FileReader();reader.addEventListener(&quot;load&quot;, function () &#123; preview.src = reader.result;&#125;, false);document.getElementById(&#x27;file&#x27;).addEventListener(&#x27;change&#x27;, function (event) &#123; var file = this.files[0]; if (file) &#123; reader.readAsDataURL(file); &#125;&#125;); 读取多个文件示例 - CodePen dataURL是base64编码的数据格式，展示类型为字符串，形如: data:image/jpeg;base64,/9j/4QXERXhpZgAATU... 将 dataURL 转为 blob对象: 1234567891011function dataURLToBlob (dataurl) &#123; let arr = dataurl.split(&#x27;,&#x27;); let mime = arr[0].match(/:(.*?);/)[1]; let bstr = atob(arr[1]); let n = bstr.length; let u8arr = new Uint8Array(n); while (n--) &#123; u8arr[n] = bstr.charCodeAt(n); &#125; return new Blob([u8arr], &#123; type: mime &#125;);&#125; 结合上例，根据已有的 &lt;img&gt; 对象创建一个 File 对象: 12345678reader.addEventListener(&quot;load&quot;, function () &#123; preview.src = reader.result; var blob = dataURLToBlob(reader.result); var newFile = new File([blob], &#x27;test.jpeg&#x27;, &#123;type: blob.type&#125;); console.log(newFile.name); // test.jpeg console.log(newFile.type); console.log(newFile.size);&#125;, false); URL.createObjectURL将图片文件转换成 data:URL 格式供 &lt;img&gt; 元素展示，除了使用 fileReader.readAsDataURL外，还可以使用 URL.createObjectURL方法。 URL.createObjectURL(blob) 方法返回一个 blob: 开头的字符串，指向文件在内存中的地址。 123456789&lt;input type=&quot;file&quot; id=&#x27;file&#x27; accept=&quot;image/png, image/jpg, image/jpeg, image/gif&quot; /&gt;&lt;br /&gt;&lt;img src=&quot;&quot; alt=&quot;Image preview...&quot;&gt;var preview = document.querySelector(&#x27;img&#x27;);document.getElementById(&#x27;file&#x27;).addEventListener(&#x27;change&#x27;, function (event) &#123; var file = this.files[0]; if (file) &#123; preview.src = URL.createObjectURL(file); &#125;&#125;); 综合实例综合以上，可以实现一个简单的粘贴图片并显示的功能。HTML5提供的内容编辑功能，可以粘贴部分图片，例如从网页上复制的图片。但是使用截图工具截取的图片无法粘贴显示，而且从网页上复制的图片会带有原来的样式，其图片url也是原来图片的指向。我们使用以下代码可以统一这两种粘贴操作，实现统一的效果。 123456789101112131415161718192021222324252627&lt;div id=&quot;comment&quot; contenteditable&gt;&lt;/div&gt;#comment&#123; border: 1px solid #ccc; min-height: 500px; padding: 10px;&#125;#comment:focus &#123; border-color: #ccc; outline: none;&#125;.img-paste &#123; max-width: 100%;&#125;var comment = document.getElementById(&#x27;comment&#x27;);comment.addEventListener(&#x27;paste&#x27;, function(event) &#123; console.log(event); var item = event.clipboardData.files[0]; if (item &amp;&amp; /image/.test(item.type)) &#123; var img = new Image(); img.src = URL.createObjectURL(item); img.className = &#x27;img-paste&#x27;; this.appendChild(img); event.preventDefault(); &#125;&#125;, false); 实例效果可以查看这里。 参考链接 using files from web apps - MDN Blob - MDN MIME types - Wikipedia MIME TYPES - MDN FileReader —— MDN MIME types - w3school [Blob/DataURL/canvas/image的相互转换](","categories":[{"name":"javascript","slug":"javascript","permalink":"http://example.com/categories/javascript/"}],"tags":[{"name":"file","slug":"file","permalink":"http://example.com/tags/file/"}]},{"title":"Docker容器的使用","slug":"Docker容器的使用","date":"2020-09-14T08:23:54.000Z","updated":"2020-09-14T08:32:36.701Z","comments":true,"path":"2020/09/14/Docker容器的使用/","link":"","permalink":"http://example.com/2020/09/14/Docker%E5%AE%B9%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Docker容器的使用Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。Docker通常用于如下场景： web应用的自动化打包和发布； 自动化测试和持续集成、发布； 在服务型环境中部署和调整数据库或其他的后台应用； 从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境。 ubuntu 上安装： wget -qO- https://get.docker.com/ | sh 或者 sudo apt-get install docker Docker系统有两个程序：docker服务端和docker客户端。其中docker服务端是一个服务进程，管理着所有的容器。docker客户端则扮演着docker服务端的远程控制器，可以用来控制docker的服务端进程。大部分情况下，docker服务端和客户端运行在一台机器上。 搜索可用的docker镜像使用docker最简单的方式莫过于从现有的容器镜像开始。Docker官方网站专门有一个页面来存储所有可用的镜像，网址是：index.docker.io。你可以通过浏览这个网页来查找你想要使用的镜像，或者使用命令行的工具来检索。目标：学会使用命令行的工具来检索名字叫做tutorial的镜像。提示：命令行的格式为：docker search 镜像名字 学会使用docker命令来下载镜像下载镜像的命令非常简单，使用docker pull命令即可。(译者按：docker命令和git有一些类似的地方）。在docker的镜像索引网站上面，镜像都是按照 用户名/ 镜像名的方式来存储的。有一组比较特殊的镜像，比如ubuntu这类基础镜像，经过官方的验证，值得信任，可以直接用 镜像名来检索到。目标：通过docker命令下载tutorial镜像。提示：执行pull命令的时候要写完整的名字，比如”learn/tutorial”。 查看安装的镜像： 在docker容器中运行hello world!docker容器可以理解为在沙盒中运行的进程。这个沙盒包含了该进程运行所必须的资源，包括文件系统、系统类库、shell 环境等等。但这个沙盒默认是不会运行任何程序的。你需要在沙盒中运行一个进程来启动某一个容器。这个进程是该容器的唯一进程，所以当该进程结束的时候，容器也会完全的停止。目标：在我们刚刚下载的镜像中输出”hello word”。为了达到这个目的，我们需要在这个容器中运行”echo”命令，输出”hello word”。提示：docker run命令有两个参数，一个是镜像名，一个是要在镜像中运行的命令。 在容器中安装新的程序下一步我们要做的事情是在容器里面安装一个简单的程序(ping)。我们之前下载的tutorial镜像是基于ubuntu的，所以你可以使用ubuntu的apt-get命令来安装ping程序：apt-get install -y ping。备注：apt-get 命令执行完毕之后，容器就会停止，但对容器的改动不会丢失。目标：在learn/tutorial镜像里面安装ping程序。提示：在执行apt-get 命令的时候，要带上-y参数。如果不指定-y参数的话，apt-get命令会进入交互模式，需要用户输入命令来进行确认，但在docker环境中是无法响应这种交互的。 保存对容器的修改当你对某一个容器做了修改之后（通过在容器中运行某一个命令），可以把对容器的修改保存下来，这样下次可以从保存后的最新状态运行该容器。docker中保存状态的过程称之为committing，它保存的新旧状态之间的区别，从而产生一个新的版本。目标：首先使用docker ps -l命令获得安装完ping命令之后容器的id。然后把这个镜像保存为learn/ping。提示：1. 运行docker commit，可以查看该命令的参数列表。2. 你需要指定要提交保存容器的ID。(译者按：通过docker ps -l 命令获得)3. 无需拷贝完整的id，通常来讲最开始的三至四个字母即可区分。（译者按：非常类似git里面的版本号) 运行新的镜像ok，到现在为止，你已经建立了一个完整的、自成体系的docker环境，并且安装了ping命令在里面。它可以在任何支持docker环境的系统中运行啦！(译者按：是不是很神奇呢？)让我们来体验一下吧！目标：在新的镜像中运行ping www.google.com命令。提示：一定要使用新的镜像名learn/ping来运行ping命令。(译者按：最开始下载的learn/tutorial镜像中是没有ping命令的) 查看所有的容器列表的命令是：docker ps -a ，显示最近一个容器的命令是：docker ps -l，更新太快了- - 发布docker镜像现在我们已经验证了新镜像可以正常工作，下一步我们可以将其发布到官方的索引网站。还记得我们最开始下载的learn/tutorial镜像吧，我们也可以把我们自己编译的镜像发布到索引页面，一方面可以自己重用，另一方面也可以分享给其他人使用。runoob@runoob:~# docker run -d -P training/webapp python app.py-d:让容器在后台运行。-P:将容器内部使用的网络端口映射到我们使用的主机上。docker logs [ID或者名字] 可以查看容器内部的标准输出。停止运行runoob@runoob:~$ docker stop wizardly_chandrasekhar 我们可以使用 docker rm 命令来删除不需要的容器 删除容器时，容器必须是停止状态runoob@runoob:~$ docker rm wizardly_chandrasekhar docker run 只在第一次运行时使用，将镜像放到容器中，以后再次启动这个容器时，只需要使用命令docker start 即可。docker run**相当于执行了两步操作：将镜像放入容器中（**docker create**）**,**然后将容器启动，使之变成运行时容器（**docker start**）。**","categories":[{"name":"容器","slug":"容器","permalink":"http://example.com/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"MySQL创建用户与授权","slug":"MySQL创建用户与授权","date":"2020-09-14T08:18:16.000Z","updated":"2020-09-14T08:19:12.809Z","comments":true,"path":"2020/09/14/MySQL创建用户与授权/","link":"","permalink":"http://example.com/2020/09/14/MySQL%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%E4%B8%8E%E6%8E%88%E6%9D%83/","excerpt":"","text":"MySQL创建用户与授权一. 创建用户命令:CREATE USER ‘username’@’host’ IDENTIFIED BY ‘password’; 说明： username：你将创建的用户名 host：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符% password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器 例子：CREATE USER ‘dog’@’localhost’ IDENTIFIED BY ‘123456’; CREATE USER ‘pig’@’192.168.1.101_’ IDENDIFIED BY ‘123456’; CREATE USER ‘pig’@’%’ IDENTIFIED BY ‘123456’; CREATE USER ‘pig’@’%’ IDENTIFIED BY ‘’; CREATE USER ‘pig’@’%’; 二. 授权:命令:GRANT privileges ON databasename.tablename TO ‘username’@’host’ 说明: privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL databasename：数据库名 tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用表示，如.* 例子: GRANT SELECT, INSERT ON test.user TO ‘pig’@’%’; GRANT ALL ON . TO ‘pig’@’%’; GRANT ALL ON maindataplus.* TO ‘pig’@’%’; 注意:用以上命令授权的用户不能给其它用户授权，如果想让该用户可以授权，用以下命令: GRANT privileges ON databasename.tablename TO ‘username’@’host’ WITH GRANT OPTION; 三.设置与更改用户密码命令:SET PASSWORD FOR ‘username’@’host’ = PASSWORD(‘newpassword’); 如果是当前登陆用户用: SET PASSWORD = PASSWORD(“newpassword”); 例子:SET PASSWORD FOR ‘pig’@’%’ = PASSWORD(“123456“); 四. 撤销用户权限命令:REVOKE privilege ON databasename.tablename FROM ‘username’@’host’; 说明:privilege, databasename, tablename：同授权部分 例子:REVOKE SELECT ON . FROM ‘pig’@’%’; 注意:假如你在给用户‘pig’@’%’授权的时候是这样的（或类似的）：GRANT SELECT ON test.user TO ‘pig’@’%’，则在使用REVOKE SELECT ON . FROM ‘pig’@’%’;命令并不能撤销该用户对test数据库中user表的SELECT 操作。相反，如果授权使用的是GRANT SELECT ON . TO ‘pig’@’%’;则REVOKE SELECT ON test.user FROM ‘pig’@’%’;命令也不能撤销该用户对test数据库中user表的Select权限。 具体信息可以用命令SHOW GRANTS FOR ‘pig’@’%’; 查看。 五.删除用户命令:DROP USER ‘username’@’host’;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"YML简介","slug":"YML简介","date":"2020-09-12T06:03:43.000Z","updated":"2020-09-14T08:11:01.762Z","comments":true,"path":"2020/09/12/YML简介/","link":"","permalink":"http://example.com/2020/09/12/YML%E7%AE%80%E4%BB%8B/","excerpt":"","text":"一、YML是什么YAML (YAML Ain’t a Markup Language)YAML不是一种标记语言，通常以.yml为后缀的文件，是一种直观的能够被电脑识别的数据序列化格式，并且容易被人类阅读，容易和脚本语言交互的，可以被支持YAML库的不同的编程语言程序导入，一种专门用来写配置文件的语言。可用于如： Java，C/C++, Ruby, Python, Perl, C#, PHP等。 二、YML的优点 YAML易于人们阅读。 YAML数据在编程语言之间是可移植的。 YAML匹配敏捷语言的本机数据结构。 YAML具有一致的模型来支持通用工具。 YAML支持单程处理。 YAML具有表现力和可扩展性。 YAML易于实现和使用。 三、YML语法1.约定 k: v 表示键值对关系，冒号后面必须有一个空格 使用空格的缩进表示层级关系，空格数目不重要，只要是左对齐的一列数据，都是同一个层级的 大小写敏感 缩进时不允许使用Tab键，只允许使用空格。 松散表示，java中对于驼峰命名法，可用原名或使用-代替驼峰，如java中的lastName属性,在yml中使用lastName或 last-name都可正确映射。 2.键值关系(以java语言为例，其它语言类似)对于键与值主要是看能否表示以下内容。普通的值(数字、字符串、布尔)、日期、对象、数组、集合等。 1) 普通值(字面量)k: v：字面量直接写； 字符串默认不用加上单引号或者双绰号； “”: 双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思 ​ name: “zhangsan \\n lisi”：输出；zhangsan 换行 lisi ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据 12345name1: zhangsanname2: &#x27;zhangsan \\n lisi&#x27;name3: &quot;zhangsan \\n lisi&quot;age: 18flag: true 2)日期1date: 2020/09/12 3)对象(属性和值)、Map(键值对) 在下一行来写对象的属性和值的关系，注意缩进 123people: name: zhangsan age: 20 行内写法: 1people: &#123;name:zhangsan,age: 20&#125; 4)数组、list、set用- 值表示数组中的一个元素 1234pets: - dog - pig - cat 行内写法 1pets: [dog,pig,cat] 5)数组对象、list对象、set对象123456peoples: - name: zhangsan age: 22 - name: lisi age: 20 - &#123;name: wangwu,age: 18&#125; 6)java代码示例java代码(省略get,set方法) 12345678910111213141516public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Dog&gt; lists; private Dog dog; private String[] arr;｝public class Dog &#123; private String name; private Integer age;&#125; 对应的yml 123456789101112131415161718person: boss: false maps: k1: v1 k2: 14 lists: - name: d1 age: 2 - name: d2 age: 3 - &#123;name: d3,age: 4&#125; birth: 2020/09/12 dog: name: p_dog age: 15 age: 13 last-name: 张三 arr: [s1,s2,s3] 3.文档块对于测试环境，预生产环境，生产环境可以使用不同的配置，如果只想写到一个文件中，yml与是支持的,每个块用—-隔开 12345678910111213141516171819server: port: 8081spring: profiles: active: prod #激活对应的文档块---server: port: 8083spring: profiles: dev #指定属于哪个环境---server: port: 8084spring: profiles: prod #指定属于哪个环境","categories":[{"name":"脚本","slug":"脚本","permalink":"http://example.com/categories/%E8%84%9A%E6%9C%AC/"}],"tags":[{"name":"YML","slug":"YML","permalink":"http://example.com/tags/YML/"}]},{"title":"hexo+github.io博客搭建📖","slug":"hexo-github-io博客搭建","date":"2020-09-11T09:17:59.000Z","updated":"2020-09-14T08:11:28.939Z","comments":true,"path":"2020/09/11/hexo-github-io博客搭建/","link":"","permalink":"http://example.com/2020/09/11/hexo-github-io%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","excerpt":"","text":"什么是 Hexo？ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 需要安装的软件环境 Node.js [nodeJS官网] https://nodejs.org/en/ 安装 hexo： npm install hero-cli -g 使用hexo创建博客目录并启动： hexo init myBlog cd myBlog yarn hexo s 更换hexo主题：git形式： cd 到博客主目录下 git clone https://github.com/theme-next/hexo-theme-next themes/next 修改根目录下的配置文件 [_config.yml] 中 theme: next 然后启动 hexo clean hero s 部署截图 配置网站 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 keywords 网站的关键词。支援多个关键词。 author 您的名字 language 网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。 timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。 网址 参数 描述 默认值 url 网址 root 网站根目录 permalink 文章的 永久链接 格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 pretty_urls 改写 permalink 的值来美化 URL pretty_urls.trailing_index 是否在永久链接中保留尾部的 index.html，设置为 false 时去除 true pretty_urls.trailing_html 是否在永久链接中保留尾部的 .html, 设置为 false 时去除 (对尾部的 index.html无效) 目录 参数 描述 默认值 source_dir 资源文件夹，这个文件夹用来存放内容。 source public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public tag_dir 标签文件夹 tags archive_dir 归档文件夹 archives category_dir 分类文件夹 categories code_dir Include code 文件夹，source_dir 下的子目录 downloads/code i18n_dir 国际化（i18n）文件夹 :lang 文章 参数 描述 默认值 new_post_name 新文章的文件名称 :title.md default_layout 预设布局 post auto_spacing 在中文和英文之间加入空格 false titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true external_link.enable 在新标签中打开链接 true external_link.field 对整个网站（site）生效或仅对文章（post）生效 site external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 [] filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置, see Highlight.js section for usage guide 发布文章文章资源文件夹 对于那些想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说，Hexo也提供了更组织化的方式来管理资源。这个稍微有些复杂但是管理资源非常方便的功能可以通过将 config.yml 文件中的 post_asset_folder 选项设为 true 来打开。 1post_asset_folder: true 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] &lt;title&gt; 命令创建新文章时自动创建一个文件夹。这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过相对路径来引用它们，这样你就得到了一个更简单而且方便得多的工作流。 相关文档[hexo中文文档：] https://hexo.io/zh-cn/docs/","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://example.com/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-09-11T03:40:32.735Z","updated":"2020-09-11T03:40:32.736Z","comments":true,"path":"2020/09/11/hello-world/","link":"","permalink":"http://example.com/2020/09/11/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"架构","slug":"架构","permalink":"http://example.com/categories/%E6%9E%B6%E6%9E%84/"},{"name":"敏捷开发","slug":"敏捷开发","permalink":"http://example.com/categories/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/"},{"name":"服务","slug":"服务","permalink":"http://example.com/categories/%E6%9C%8D%E5%8A%A1/"},{"name":"tools","slug":"tools","permalink":"http://example.com/categories/tools/"},{"name":"javascript","slug":"javascript","permalink":"http://example.com/categories/javascript/"},{"name":"容器","slug":"容器","permalink":"http://example.com/categories/%E5%AE%B9%E5%99%A8/"},{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"脚本","slug":"脚本","permalink":"http://example.com/categories/%E8%84%9A%E6%9C%AC/"},{"name":"环境搭建","slug":"环境搭建","permalink":"http://example.com/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"unix","slug":"unix","permalink":"http://example.com/tags/unix/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"Serverless","slug":"Serverless","permalink":"http://example.com/tags/Serverless/"},{"name":"中间件","slug":"中间件","permalink":"http://example.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"微服务","slug":"微服务","permalink":"http://example.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"DevOps","slug":"DevOps","permalink":"http://example.com/tags/DevOps/"},{"name":"nginx","slug":"nginx","permalink":"http://example.com/tags/nginx/"},{"name":"工具","slug":"工具","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7/"},{"name":"file","slug":"file","permalink":"http://example.com/tags/file/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"YML","slug":"YML","permalink":"http://example.com/tags/YML/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"}]}